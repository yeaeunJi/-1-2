{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNxWdrDiLnMQpdrRHQSlCpB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeaeunJi/deep_learning-/blob/main/Word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV6XN6cUK0eX"
      },
      "source": [
        "## 추론기반 기법과 신경망\r\n",
        "- 단어를 벡터로 표현하는 방법 중 성공적인 기법은 크게 '통계 기반 기법'과 '추론 기반 기법'이 있음\r\n",
        "- 두 방법 모두 분포 가설을 기반으로 하지만 단어의 의미를 얻는 방식이 다름\r\n",
        "  - 분포 가설 : 단어의 의미는 주변 단어에 의해 형성된다는 가설\r\n",
        "\r\n",
        "### 통계 기반 기법의 문제점\r\n",
        "- 통계 기반 기법은 주변 단어의 빈도를 집계하여 단어를 표현\r\n",
        "  - 단어의 동시발생 행렬 --> SVD로 차원 축소하여 밀집 벡터로 단어의 분산 표현을 얻음\r\n",
        "- 통계 기반 기법 시 코퍼스(말뭉치)의 어휘 수를 N이라고 했을때, N * N의 크기의 행렬을 만들고, 이 행렬에 SVD를 적용하는 비용은  O(n의 3제곱)임. 따라서 규모가 큰 말뭉치에 적용 시 상당한 컴퓨팅 자원과 시간이 소요됨\r\n",
        "\r\n",
        "- 통계 기반 기법은 코퍼스 전체의 통계(동시발생 행렬과 PPMI 등)을 통해 1회의 처리(SVD)만에 단어의 분산 표현을 얻음(배치학습)\r\n",
        "\r\n",
        "- 추론 기반 기법에서는 미니배치로 대규모의 학습 데이터의 일부들을 사용하여 순자적으로 학습(미니배치학습)\r\n",
        "\r\n",
        "- 여러 머신과 여러 GPU를 이용한 병렬 계산도 가능해져 학습 속도가 향상 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXSIAaWXNXPT"
      },
      "source": [
        "### 추론 기반 기법 개요\r\n",
        "- 주변 단어(맥락)이 주어졌을 때 목표 단어에 어떤 단어가 들어가는지를 추측하는 작업을 반복하여 풀며 단어의 출현 패턴을 학습\r\n",
        "- 맥락을 입력하면 모델은 각 단어의 출현 확률을 출력하는 작업을 통해 모델이 올바른 추축을 하도록 학습시키고, 그 결과로 단어의 분산 표현을 얻음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLAmEMLhN45C"
      },
      "source": [
        "### 신경망에서의 단어 처리\r\n",
        "- 신경망에서는 단어를 '고정 길이의 벡터'로 변환해야 하는데, 이때 사용하는 기법에는 대표적으로 원핫(one-hot) 표현 또는 원핫 벡터로 변환\r\n",
        "  - 원핫 표현 : 벡터의 원소 중 하나만 1이고 나머지 원소는 모두 0인 벡터\r\n",
        "  - 총 어휘 수 만큼의 원소를 갖는 벡터에 인덱스가 단어 ID와 같다면 1, 아니라면 0으로 설정\r\n",
        "- 단어를 고정 길이 벡터로 변환하면 신경망의 입력층의 뉴런의 수를 고정 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvzZA0UrKxf-",
        "outputId": "686f4a7b-70d5-48c7-d8cc-61de8adbeb7f"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "c = np.array([[1, 0, 0, 0, 0, 0, 0]]) # 입력층 노드 수 7\r\n",
        "W = np.random.randn(7, 3) # 은닉층의 노드 수 3 이므로 완전연결계층의 가중치는 7*3크기\r\n",
        "h = np.matmul(c, W) # 중간 노드 값\r\n",
        "print(h) # 단어 ID에 대응하는 원소만 1이므로 c*W의 행렬곱은 가중치의 행벡터 하나를 뽑은 것과 같음. 따라서 다음에 개선할 예정\r\n",
        "print(W[0]) "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.73860873 -1.46469447  0.46299378]]\n",
            "[ 1.73860873 -1.46469447  0.46299378]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_tIWhsyTOSl"
      },
      "source": [
        "# 행렬의 곱을 수행하는 계층 클래스\r\n",
        "class MatMul:\r\n",
        "    def __init__(self, W):\r\n",
        "        self.params = [W]\r\n",
        "        self.grads = [np.zeros_like(W)]\r\n",
        "        self.x = None\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        W, = self.params\r\n",
        "        out = np.dot(x, W)\r\n",
        "        self.x = x\r\n",
        "        return out\r\n",
        "\r\n",
        "    def backward(self, dout):\r\n",
        "        W, = self.params\r\n",
        "        dx = np.dot(dout, W.T)\r\n",
        "        dW = np.dot(self.x.T, dout)\r\n",
        "        self.grads[0][...] = dW\r\n",
        "        return dx"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCDToYpYPPvV"
      },
      "source": [
        "# 앞에서 구현했던 MatMul 계층을 사용하여 구현할수도 있음(작동되지 않은 예시 코드로 MatMul은 )\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "c = np.array([[1, 0, 0, 0, 0, 0, 0]]) # 입력층 노드 수 7\r\n",
        "W = np.random.randn(7, 3) # 은닉층의 노드 수 3 이므로 완전연결계층의 가중치는 7*3크기\r\n",
        "layer = MatMul(W)\r\n",
        "h = layer.forward(c)\r\n",
        "print(h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tob8xUL_QTq7"
      },
      "source": [
        "## 단순한 word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N64kwLQwQZmM"
      },
      "source": [
        "### CBOW(continuous bag-of-words)\r\n",
        "- CBOW 모델은 주변 단어(맥락)로부터 타겟 단어(중앙 단어)를 추측하는 용도의 신경망\r\n",
        "- 맥락을 입력으로 받는 모델이므로 입력할 맥락을 원핫 표현으로 변환하는 전처리 작업 필요\r\n",
        "\r\n",
        "- 2개의 맥락을 사용한다면 입력층이 2개가 되며, 은닉층을 거쳐 출력층에 도달\r\n",
        "  - 두 입력층에서 은닉층으로는 같은 완전연결계층(가중치공유)이 처리하고, 은닉층에서 출력층 뉴런으로의 변환은 다른 완전연결계층이 처리\r\n",
        "  - 입력층이 여러개일 경우 전체의 평균 값이 은닉층의 값이 됨\r\n",
        "  - 출력층 각각의 뉴런은 각각의 단어에 대응하고, 각 단어의 score(점수)임\r\n",
        "  - 이 점수에 소프트맥스 함수를 적용하면 확률을 얻을 수 있음\r\n",
        "\r\n",
        "- 입력층에서 은닉층으로의 변환 시 사용되는 가중치가 단어의 분산표현으로 사용됨\r\n",
        "  - 가중치의 각 행이 해당 단어의 분산 표현\r\n",
        "  - 학습을 진행할수록 맥락에서 출현하는 단어를 잘 추측하도록 분산 표현들이 갱신됨(단어의 의미도 녹아들어 있는 벡터를 얻게됨)\r\n",
        "\r\n",
        "- 은닉층의 뉴런 수를 입력층의 뉴런 수보다 적게 함\r\n",
        "  - 단어 예측에 필요한 정보를 간결하게 담고, 밀집벡터 표현을 얻을 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AwXZ1zAQEHA",
        "outputId": "66e8c784-f243-47af-fd32-2fa5da6a74dd"
      },
      "source": [
        "# 샘플 맥락 데이터\r\n",
        "c0 = np.array([[1,0,0,0,0,0,0]])\r\n",
        "c1 = np.array([[0,0,1,0,0,0,0]])\r\n",
        "\r\n",
        "# 가중치 초기화\r\n",
        "W_in = np.random.randn(7,3)\r\n",
        "W_out = np.random.randn(3,7)\r\n",
        "\r\n",
        "# 계층 생성\r\n",
        "in_layer0 = MatMul(W_in)\r\n",
        "in_layer1 = MatMul(W_in) # 입력층의 MatMul 게층은 가중치 W_in을 공유\r\n",
        "out_layer = MatMul(W_out)\r\n",
        "\r\n",
        "# 순전파\r\n",
        "h0 = in_layer0.forward(c0)\r\n",
        "h1 = in_layer1.forward(c1)\r\n",
        "h = 0.5 * (h0+h1)\r\n",
        "s = out_layer.forward(h)\r\n",
        "\r\n",
        "print(s)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.2196541  -0.61564545 -0.006366    0.75285873 -0.72388051 -1.04155523\n",
            "   0.09959919]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js1Y2_y8UTD8"
      },
      "source": [
        "### CBOW 모델의 학습\r\n",
        "- 위에서 얻은 각 단어의 점수에 소프트맥스 함수를 적용하면 '확률'을 얻을 수 있음\r\n",
        "  - 이 확률은 맥락(전후 단어)이 주어져있을 때, 그 중앙에 어떤 단어가 출현하는 지를 나타냄\r\n",
        "\r\n",
        "- 다중 클래스 분류를 수행하는 신경망이므로 소프트맥스와 교차 엔트로피 오차를 이용하여 신경망을 학습시킴\r\n",
        "  - 소프트맥스 함수 : 출력층에서 얻은 점수를 확률로 변환\r\n",
        "  - 교차 엔트로피 오차 : 소프트맥스 함수로 얻은 확률과 정답 레이블을 통해 얻은 교차 엔트로프 오차 값을 손실로 사용 가능\r\n",
        "\r\n",
        "- 입력 측 가중치는 각 행이 각 단어의 분산 표현에 해당하고, 출력 측 가중치에도 단어의 의미가 인코딩된 벡터가 저장되어 있다고 생각 가능(열발향으로 각 단어의 분산 표현 저장)\r\n",
        "  - 입력측의 가중치만 이용하거나 출력 측의 가중치만 이용하거나 모두 이용 가능\r\n",
        "  - word2vec(특히 skip-gram 모델)에서는 첫번째가 대중적인 선택임"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQCTdbTgW1cV"
      },
      "source": [
        "##### 전처리\r\n",
        "- 말뭉치로부터 추측을 목표로 하는 중앙 단어(타깃)과 그 주변 단어인 '맥락'을 추출해야 함\r\n",
        "- 타깃 : 양끝의 window size만큼의 단어를 제외한 모든 단어에 대해 수행\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7mQoL7qTy2g"
      },
      "source": [
        "# 말뭉치를 단어 ID로 변환하는 함수\r\n",
        "def preprocess(text):\r\n",
        "    text = text.lower()\r\n",
        "    text = text.replace('.', ' .')\r\n",
        "    words = text.split(' ')\r\n",
        "\r\n",
        "    word_to_id = {}\r\n",
        "    id_to_word = {}\r\n",
        "    for word in words:\r\n",
        "        if word not in word_to_id:\r\n",
        "            new_id = len(word_to_id)\r\n",
        "            word_to_id[word] = new_id\r\n",
        "            id_to_word[new_id] = word\r\n",
        "\r\n",
        "    corpus = np.array([word_to_id[w] for w in words])\r\n",
        "\r\n",
        "    return corpus, word_to_id, id_to_word"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raFovQxuW1CS",
        "outputId": "880fd878-b225-40f6-987f-f17d48ec7ae5"
      },
      "source": [
        "text = 'You say goodbye and I say hello.'\r\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\r\n",
        "print(corpus)\r\n",
        "print(id_to_word)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 1 5 6]\n",
            "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR1k9q-FXK8I"
      },
      "source": [
        "# 단어 ID의 배열인 corpus에서 맥락과 타깃 추출하는 함수\r\n",
        "def create_contexts_target(corpus, window_size=1) :\r\n",
        "  target = corpus[window_size : -window_size] # 타겟은 양쪽 끝의 윈도우사이즈만큼을 제외하여 추출\r\n",
        "  contexts = []\r\n",
        "\r\n",
        "  for idx in range(window_size, len(corpus)-window_size) : # 타겟 단어가 될 수 있는 단어들\r\n",
        "    cs = [] # 해당 타겟 단어 주변 맥락 단어를 담을 배열\r\n",
        "\r\n",
        "    for t in range(-window_size, window_size+1) : # 윈도우 크기의 범위\r\n",
        "      if t == 0 : # 윈도우 크기 범위 안에 있는 단어가 타겟단어일 경우 제외\r\n",
        "        continue\r\n",
        "      cs.append(corpus[idx+t]) \r\n",
        "    \r\n",
        "    contexts.append(cs) # 전체 말뭉치에 대한 맥락\r\n",
        "\r\n",
        "  return np.array(contexts), np.array(target)\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMFTYKDiYr16",
        "outputId": "bd0b444e-45de-4cf1-b73c-63cacff316b2"
      },
      "source": [
        "contexts, target = create_contexts_target(corpus, window_size=1)\r\n",
        "print(contexts)\r\n",
        "print(target)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 2]\n",
            " [1 3]\n",
            " [2 4]\n",
            " [3 1]\n",
            " [4 5]\n",
            " [1 6]]\n",
            "[1 2 3 4 1 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7sxzLFGY0N8"
      },
      "source": [
        "# 추출한 맥락과 타깃의 각 원소가 단어 ID이므로 이를 원핫 표현으로 변환\r\n",
        "def convert_one_hot(corpus, vocab_size):\r\n",
        "    '''원핫 표현으로 변환\r\n",
        "    :param corpus: 단어 ID 목록(1차원 또는 2차원 넘파이 배열)\r\n",
        "    :param vocab_size: 어휘 수\r\n",
        "    :return: 원핫 표현(2차원 또는 3차원 넘파이 배열)\r\n",
        "    '''\r\n",
        "    N = corpus.shape[0]\r\n",
        "\r\n",
        "    if corpus.ndim == 1:\r\n",
        "        one_hot = np.zeros((N, vocab_size), dtype=np.int32)\r\n",
        "        for idx, word_id in enumerate(corpus):\r\n",
        "            one_hot[idx, word_id] = 1\r\n",
        "\r\n",
        "    elif corpus.ndim == 2:\r\n",
        "        C = corpus.shape[1]\r\n",
        "        one_hot = np.zeros((N, C, vocab_size), dtype=np.int32)\r\n",
        "        for idx_0, word_ids in enumerate(corpus):\r\n",
        "            for idx_1, word_id in enumerate(word_ids):\r\n",
        "                one_hot[idx_0, idx_1, word_id] = 1\r\n",
        "\r\n",
        "    return one_hot"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdI3HrSeZ1CG",
        "outputId": "3b9c25c5-069e-4545-ffb5-7769411360db"
      },
      "source": [
        "vocab_size = len(word_to_id)\r\n",
        "target = convert_one_hot(target, vocab_size)\r\n",
        "contexts = convert_one_hot(contexts, vocab_size)\r\n",
        "\r\n",
        "print(contexts)\r\n",
        "print(target)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[1 0 0 0 0 0 0]\n",
            "  [0 0 1 0 0 0 0]]\n",
            "\n",
            " [[0 1 0 0 0 0 0]\n",
            "  [0 0 0 1 0 0 0]]\n",
            "\n",
            " [[0 0 1 0 0 0 0]\n",
            "  [0 0 0 0 1 0 0]]\n",
            "\n",
            " [[0 0 0 1 0 0 0]\n",
            "  [0 1 0 0 0 0 0]]\n",
            "\n",
            " [[0 0 0 0 1 0 0]\n",
            "  [0 0 0 0 0 1 0]]\n",
            "\n",
            " [[0 1 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 1]]]\n",
            "[[0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7wzjh5-aMCC"
      },
      "source": [
        "## CBOW 모델 구현\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nrf4bdjaIcV"
      },
      "source": [
        "def softmax(x):\r\n",
        "    if x.ndim == 2:\r\n",
        "        x = x - x.max(axis=1, keepdims=True)\r\n",
        "        x = np.exp(x)\r\n",
        "        x /= x.sum(axis=1, keepdims=True)\r\n",
        "    elif x.ndim == 1:\r\n",
        "        x = x - np.max(x)\r\n",
        "        x = np.exp(x) / np.sum(np.exp(x))\r\n",
        "\r\n",
        "    return x\r\n",
        "    \r\n",
        "def cross_entropy_error(y, t):\r\n",
        "    if y.ndim == 1:\r\n",
        "        t = t.reshape(1, t.size)\r\n",
        "        y = y.reshape(1, y.size)\r\n",
        "        \r\n",
        "    # 정답 데이터가 원핫 벡터일 경우 정답 레이블 인덱스로 변환\r\n",
        "    if t.size == y.size:\r\n",
        "        t = t.argmax(axis=1)\r\n",
        "             \r\n",
        "    batch_size = y.shape[0]\r\n",
        "\r\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\r\n",
        "\r\n",
        "\r\n",
        "class SoftmaxWithLoss:\r\n",
        "    def __init__(self):\r\n",
        "        self.params, self.grads = [], []\r\n",
        "        self.y = None  # softmax의 출력\r\n",
        "        self.t = None  # 정답 레이블\r\n",
        "\r\n",
        "    def forward(self, x, t):\r\n",
        "        self.t = t\r\n",
        "        self.y = softmax(x)\r\n",
        "\r\n",
        "        # 정답 레이블이 원핫 벡터일 경우 정답의 인덱스로 변환\r\n",
        "        if self.t.size == self.y.size:\r\n",
        "            self.t = self.t.argmax(axis=1)\r\n",
        "\r\n",
        "        loss = cross_entropy_error(self.y, self.t)\r\n",
        "        return loss\r\n",
        "\r\n",
        "    def backward(self, dout=1):\r\n",
        "        batch_size = self.t.shape[0]\r\n",
        "\r\n",
        "        dx = self.y.copy()\r\n",
        "        dx[np.arange(batch_size), self.t] -= 1\r\n",
        "        dx *= dout\r\n",
        "        dx = dx / batch_size\r\n",
        "\r\n",
        "        return dx\r\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOfPnJ1xaYD0"
      },
      "source": [
        "class SimpleCBOW :\r\n",
        "  def __init__(self, vocab_size, hidden_size) :\r\n",
        "    V, H = vocab_size, hidden_size\r\n",
        "\r\n",
        "    # 가중치 초기화\r\n",
        "    W_in = 0.01 * np.random.randn(V, H).astype('f')\r\n",
        "    W_out = 0.01 * np.random.randn(H, V).astype('f')\r\n",
        "\r\n",
        "    # 계층 생성\r\n",
        "    self.in_layer0 = MatMul(W_in)\r\n",
        "    self.in_layer1 =  MatMul(W_in)\r\n",
        "    self.out_layer =  MatMul(W_out)\r\n",
        "    self.loss_layer = SoftmaxWithLoss()\r\n",
        "\r\n",
        "    # 모든 가중치와 기울기를 리스트에 모음\r\n",
        "    layers = [self.in_layer0, self.in_layer1, self.out_layer]\r\n",
        "    self.params, self.grads = [], []\r\n",
        "\r\n",
        "    for layer in layers :\r\n",
        "      self.params += layer.params\r\n",
        "      self.grads += layer.grads\r\n",
        "    \r\n",
        "    # 인스턴스 변수에 단어의 분산 표현 저장\r\n",
        "    self.word_vecs = W_in\r\n",
        "\r\n",
        "  # 신겸앙의 순전파 forward() 메서드\r\n",
        "  def forward(self, contexts, target) :\r\n",
        "    h0 = self.in_layer0.forward(contexts[:, 0])\r\n",
        "    h1 = self.in_layer1.forward(contexts[:, 1])\r\n",
        "    h = (h0+h1) * 0.5\r\n",
        "    score = self.out_layer.forward(h)\r\n",
        "    loss = self.loss_layer.forward(score, target)\r\n",
        "    return loss\r\n",
        "  \r\n",
        "  # 신경망의 역전파\r\n",
        "  def backward(self, dout=1) :\r\n",
        "    ds = self.loss_layer.backward(dout)\r\n",
        "    da = self.out_layer.backward(ds)\r\n",
        "    da *= 0.5\r\n",
        "    self.in_layer1.backward(da)\r\n",
        "    self.in_layer0.backward(da)\r\n",
        "    return None"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuiY3f2Kboxs"
      },
      "source": [
        "import numpy\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import time\r\n",
        "def clip_grads(grads, max_norm):\r\n",
        "    total_norm = 0\r\n",
        "    for grad in grads:\r\n",
        "        total_norm += np.sum(grad ** 2)\r\n",
        "    total_norm = np.sqrt(total_norm)\r\n",
        "\r\n",
        "    rate = max_norm / (total_norm + 1e-6)\r\n",
        "    if rate < 1:\r\n",
        "        for grad in grads:\r\n",
        "            grad *= rate\r\n",
        "            \r\n",
        "class Softmax:\r\n",
        "    def __init__(self):\r\n",
        "        self.params, self.grads = [], []\r\n",
        "        self.out = None\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        self.out = softmax(x)\r\n",
        "        return self.out\r\n",
        "\r\n",
        "    def backward(self, dout):\r\n",
        "        dx = self.out * dout\r\n",
        "        sumdx = np.sum(dx, axis=1, keepdims=True)\r\n",
        "        dx -= self.out * sumdx\r\n",
        "        return dx\r\n",
        "\r\n",
        "\r\n",
        "# 여러 계층에서 같은 가중치를 공유하고 있는데 params 리스트에 같은 가중치가 여러개 존재하게 되면\r\n",
        "# 책에서 구현한 옵티마이저 처리 시 동작이 정상적으로 수행되지 않을 수 있음\r\n",
        "# 따라서 매개변수 갱신 시 매개변수의 중복을 없애는  함수 사용\r\n",
        "class Trainer:\r\n",
        "    def __init__(self, model, optimizer):\r\n",
        "        self.model = model\r\n",
        "        self.optimizer = optimizer\r\n",
        "        self.loss_list = []\r\n",
        "        self.eval_interval = None\r\n",
        "        self.current_epoch = 0\r\n",
        "\r\n",
        "    def fit(self, x, t, max_epoch=10, batch_size=32, max_grad=None, eval_interval=20):\r\n",
        "        data_size = len(x)\r\n",
        "        max_iters = data_size // batch_size\r\n",
        "        self.eval_interval = eval_interval\r\n",
        "        model, optimizer = self.model, self.optimizer\r\n",
        "        total_loss = 0\r\n",
        "        loss_count = 0\r\n",
        "\r\n",
        "        start_time = time.time()\r\n",
        "        for epoch in range(max_epoch):\r\n",
        "            # 뒤섞기\r\n",
        "            idx = numpy.random.permutation(numpy.arange(data_size))\r\n",
        "            x = x[idx]\r\n",
        "            t = t[idx]\r\n",
        "\r\n",
        "            for iters in range(max_iters):\r\n",
        "                batch_x = x[iters*batch_size:(iters+1)*batch_size]\r\n",
        "                batch_t = t[iters*batch_size:(iters+1)*batch_size]\r\n",
        "\r\n",
        "                # 기울기 구해 매개변수 갱신\r\n",
        "                loss = model.forward(batch_x, batch_t)\r\n",
        "                model.backward()\r\n",
        "                params, grads = remove_duplicate(model.params, model.grads)  # 공유된 가중치를 하나로 모음\r\n",
        "                if max_grad is not None:\r\n",
        "                    clip_grads(grads, max_grad)\r\n",
        "                optimizer.update(params, grads)\r\n",
        "                total_loss += loss\r\n",
        "                loss_count += 1\r\n",
        "\r\n",
        "                # 평가\r\n",
        "                if (eval_interval is not None) and (iters % eval_interval) == 0:\r\n",
        "                    avg_loss = total_loss / loss_count\r\n",
        "                    elapsed_time = time.time() - start_time\r\n",
        "                    print('| 에폭 %d |  반복 %d / %d | 시간 %d[s] | 손실 %.2f'\r\n",
        "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, avg_loss))\r\n",
        "                    self.loss_list.append(float(avg_loss))\r\n",
        "                    total_loss, loss_count = 0, 0\r\n",
        "\r\n",
        "            self.current_epoch += 1\r\n",
        "\r\n",
        "    def plot(self, ylim=None):\r\n",
        "        x = numpy.arange(len(self.loss_list))\r\n",
        "        if ylim is not None:\r\n",
        "            plt.ylim(*ylim)\r\n",
        "        plt.plot(x, self.loss_list, label='train')\r\n",
        "        plt.xlabel('반복 (x' + str(self.eval_interval) + ')')\r\n",
        "        plt.ylabel('손실')\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "def remove_duplicate(params, grads):\r\n",
        "    '''\r\n",
        "    매개변수 배열 중 중복되는 가중치를 하나로 모아\r\n",
        "    그 가중치에 대응하는 기울기를 더한다.\r\n",
        "    '''\r\n",
        "    params, grads = params[:], grads[:]  # copy list\r\n",
        "\r\n",
        "    while True:\r\n",
        "        find_flg = False\r\n",
        "        L = len(params)\r\n",
        "\r\n",
        "        for i in range(0, L - 1):\r\n",
        "            for j in range(i + 1, L):\r\n",
        "                # 가중치 공유 시\r\n",
        "                if params[i] is params[j]:\r\n",
        "                    grads[i] += grads[j]  # 경사를 더함\r\n",
        "                    find_flg = True\r\n",
        "                    params.pop(j)\r\n",
        "                    grads.pop(j)\r\n",
        "                # 가중치를 전치행렬로 공유하는 경우(weight tying)\r\n",
        "                elif params[i].ndim == 2 and params[j].ndim == 2 and \\\r\n",
        "                     params[i].T.shape == params[j].shape and np.all(params[i].T == params[j]):\r\n",
        "                    grads[i] += grads[j].T\r\n",
        "                    find_flg = True\r\n",
        "                    params.pop(j)\r\n",
        "                    grads.pop(j)\r\n",
        "\r\n",
        "                if find_flg: break\r\n",
        "            if find_flg: break\r\n",
        "\r\n",
        "        if not find_flg: break\r\n",
        "\r\n",
        "    return params, grads"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYY5A-DFdnnZ"
      },
      "source": [
        "# 옵티마이저 Adam\r\n",
        "class Adam:\r\n",
        "    '''\r\n",
        "    Adam (http://arxiv.org/abs/1412.6980v8)\r\n",
        "    '''\r\n",
        "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\r\n",
        "        self.lr = lr\r\n",
        "        self.beta1 = beta1\r\n",
        "        self.beta2 = beta2\r\n",
        "        self.iter = 0\r\n",
        "        self.m = None\r\n",
        "        self.v = None\r\n",
        "        \r\n",
        "    def update(self, params, grads):\r\n",
        "        if self.m is None:\r\n",
        "            self.m, self.v = [], []\r\n",
        "            for param in params:\r\n",
        "                self.m.append(np.zeros_like(param))\r\n",
        "                self.v.append(np.zeros_like(param))\r\n",
        "        \r\n",
        "        self.iter += 1\r\n",
        "        lr_t = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)\r\n",
        "\r\n",
        "        for i in range(len(params)):\r\n",
        "            self.m[i] += (1 - self.beta1) * (grads[i] - self.m[i])\r\n",
        "            self.v[i] += (1 - self.beta2) * (grads[i]**2 - self.v[i])\r\n",
        "            \r\n",
        "            params[i] -= lr_t * self.m[i] / (np.sqrt(self.v[i]) + 1e-7)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pt4L9erIeIY8",
        "outputId": "cff24d3b-a970-4757-9986-41089610b44b"
      },
      "source": [
        "window_size = 1\r\n",
        "hidden_size = 5\r\n",
        "batch_size = 3\r\n",
        "max_epoch = 1000\r\n",
        "\r\n",
        "text = 'You say goodbye and I san hello.'\r\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\r\n",
        "\r\n",
        "vocab_size = len(word_to_id)\r\n",
        "contexts, target = create_contexts_target(corpus, window_size)\r\n",
        "target = convert_one_hot(target, vocab_size)\r\n",
        "contexts = convert_one_hot(contexts, vocab_size)\r\n",
        "\r\n",
        "model = SimpleCBOW(vocab_size, hidden_size)\r\n",
        "optimizer = Adam()\r\n",
        "trainer = Trainer(model, optimizer)\r\n",
        "\r\n",
        "trainer.fit(contexts, target, max_epoch, batch_size)\r\n",
        "trainer.plot()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| 에폭 1 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 2 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 3 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 4 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 5 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 6 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 7 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 8 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 9 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 10 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 11 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 12 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 13 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 14 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 15 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 16 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 17 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 18 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 19 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 20 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 21 |  반복 1 / 2 | 시간 0[s] | 손실 2.08\n",
            "| 에폭 22 |  반복 1 / 2 | 시간 0[s] | 손실 2.07\n",
            "| 에폭 23 |  반복 1 / 2 | 시간 0[s] | 손실 2.07\n",
            "| 에폭 24 |  반복 1 / 2 | 시간 0[s] | 손실 2.07\n",
            "| 에폭 25 |  반복 1 / 2 | 시간 0[s] | 손실 2.07\n",
            "| 에폭 26 |  반복 1 / 2 | 시간 0[s] | 손실 2.07\n",
            "| 에폭 27 |  반복 1 / 2 | 시간 0[s] | 손실 2.07\n",
            "| 에폭 28 |  반복 1 / 2 | 시간 0[s] | 손실 2.07\n",
            "| 에폭 29 |  반복 1 / 2 | 시간 0[s] | 손실 2.07\n",
            "| 에폭 30 |  반복 1 / 2 | 시간 0[s] | 손실 2.07\n",
            "| 에폭 31 |  반복 1 / 2 | 시간 0[s] | 손실 2.07\n",
            "| 에폭 32 |  반복 1 / 2 | 시간 0[s] | 손실 2.07\n",
            "| 에폭 33 |  반복 1 / 2 | 시간 0[s] | 손실 2.07\n",
            "| 에폭 34 |  반복 1 / 2 | 시간 0[s] | 손실 2.07\n",
            "| 에폭 35 |  반복 1 / 2 | 시간 0[s] | 손실 2.06\n",
            "| 에폭 36 |  반복 1 / 2 | 시간 0[s] | 손실 2.06\n",
            "| 에폭 37 |  반복 1 / 2 | 시간 0[s] | 손실 2.06\n",
            "| 에폭 38 |  반복 1 / 2 | 시간 0[s] | 손실 2.06\n",
            "| 에폭 39 |  반복 1 / 2 | 시간 0[s] | 손실 2.06\n",
            "| 에폭 40 |  반복 1 / 2 | 시간 0[s] | 손실 2.06\n",
            "| 에폭 41 |  반복 1 / 2 | 시간 0[s] | 손실 2.06\n",
            "| 에폭 42 |  반복 1 / 2 | 시간 0[s] | 손실 2.06\n",
            "| 에폭 43 |  반복 1 / 2 | 시간 0[s] | 손실 2.06\n",
            "| 에폭 44 |  반복 1 / 2 | 시간 0[s] | 손실 2.05\n",
            "| 에폭 45 |  반복 1 / 2 | 시간 0[s] | 손실 2.05\n",
            "| 에폭 46 |  반복 1 / 2 | 시간 0[s] | 손실 2.05\n",
            "| 에폭 47 |  반복 1 / 2 | 시간 0[s] | 손실 2.05\n",
            "| 에폭 48 |  반복 1 / 2 | 시간 0[s] | 손실 2.05\n",
            "| 에폭 49 |  반복 1 / 2 | 시간 0[s] | 손실 2.05\n",
            "| 에폭 50 |  반복 1 / 2 | 시간 0[s] | 손실 2.04\n",
            "| 에폭 51 |  반복 1 / 2 | 시간 0[s] | 손실 2.05\n",
            "| 에폭 52 |  반복 1 / 2 | 시간 0[s] | 손실 2.04\n",
            "| 에폭 53 |  반복 1 / 2 | 시간 0[s] | 손실 2.04\n",
            "| 에폭 54 |  반복 1 / 2 | 시간 0[s] | 손실 2.04\n",
            "| 에폭 55 |  반복 1 / 2 | 시간 0[s] | 손실 2.04\n",
            "| 에폭 56 |  반복 1 / 2 | 시간 0[s] | 손실 2.03\n",
            "| 에폭 57 |  반복 1 / 2 | 시간 0[s] | 손실 2.03\n",
            "| 에폭 58 |  반복 1 / 2 | 시간 0[s] | 손실 2.03\n",
            "| 에폭 59 |  반복 1 / 2 | 시간 0[s] | 손실 2.02\n",
            "| 에폭 60 |  반복 1 / 2 | 시간 0[s] | 손실 2.03\n",
            "| 에폭 61 |  반복 1 / 2 | 시간 0[s] | 손실 2.02\n",
            "| 에폭 62 |  반복 1 / 2 | 시간 0[s] | 손실 2.02\n",
            "| 에폭 63 |  반복 1 / 2 | 시간 0[s] | 손실 2.01\n",
            "| 에폭 64 |  반복 1 / 2 | 시간 0[s] | 손실 2.02\n",
            "| 에폭 65 |  반복 1 / 2 | 시간 0[s] | 손실 2.02\n",
            "| 에폭 66 |  반복 1 / 2 | 시간 0[s] | 손실 2.01\n",
            "| 에폭 67 |  반복 1 / 2 | 시간 0[s] | 손실 2.01\n",
            "| 에폭 68 |  반복 1 / 2 | 시간 0[s] | 손실 2.01\n",
            "| 에폭 69 |  반복 1 / 2 | 시간 0[s] | 손실 2.00\n",
            "| 에폭 70 |  반복 1 / 2 | 시간 0[s] | 손실 2.01\n",
            "| 에폭 71 |  반복 1 / 2 | 시간 0[s] | 손실 2.00\n",
            "| 에폭 72 |  반복 1 / 2 | 시간 0[s] | 손실 2.00\n",
            "| 에폭 73 |  반복 1 / 2 | 시간 0[s] | 손실 1.98\n",
            "| 에폭 74 |  반복 1 / 2 | 시간 0[s] | 손실 2.00\n",
            "| 에폭 75 |  반복 1 / 2 | 시간 0[s] | 손실 1.99\n",
            "| 에폭 76 |  반복 1 / 2 | 시간 0[s] | 손실 1.99\n",
            "| 에폭 77 |  반복 1 / 2 | 시간 0[s] | 손실 1.98\n",
            "| 에폭 78 |  반복 1 / 2 | 시간 0[s] | 손실 1.98\n",
            "| 에폭 79 |  반복 1 / 2 | 시간 0[s] | 손실 1.99\n",
            "| 에폭 80 |  반복 1 / 2 | 시간 0[s] | 손실 1.98\n",
            "| 에폭 81 |  반복 1 / 2 | 시간 0[s] | 손실 1.97\n",
            "| 에폭 82 |  반복 1 / 2 | 시간 0[s] | 손실 1.97\n",
            "| 에폭 83 |  반복 1 / 2 | 시간 0[s] | 손실 1.97\n",
            "| 에폭 84 |  반복 1 / 2 | 시간 0[s] | 손실 1.97\n",
            "| 에폭 85 |  반복 1 / 2 | 시간 0[s] | 손실 1.96\n",
            "| 에폭 86 |  반복 1 / 2 | 시간 0[s] | 손실 1.96\n",
            "| 에폭 87 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 88 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 89 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 90 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 91 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 92 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 93 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 94 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 95 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 96 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 97 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 98 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 99 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 100 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
            "| 에폭 101 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 102 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 103 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 104 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
            "| 에폭 105 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
            "| 에폭 106 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
            "| 에폭 107 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
            "| 에폭 108 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
            "| 에폭 109 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
            "| 에폭 110 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 111 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
            "| 에폭 112 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
            "| 에폭 113 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
            "| 에폭 114 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
            "| 에폭 115 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
            "| 에폭 116 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
            "| 에폭 117 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
            "| 에폭 118 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
            "| 에폭 119 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
            "| 에폭 120 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
            "| 에폭 121 |  반복 1 / 2 | 시간 0[s] | 손실 1.78\n",
            "| 에폭 122 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
            "| 에폭 123 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
            "| 에폭 124 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
            "| 에폭 125 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
            "| 에폭 126 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
            "| 에폭 127 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
            "| 에폭 128 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
            "| 에폭 129 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
            "| 에폭 130 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
            "| 에폭 131 |  반복 1 / 2 | 시간 0[s] | 손실 1.78\n",
            "| 에폭 132 |  반복 1 / 2 | 시간 0[s] | 손실 1.75\n",
            "| 에폭 133 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
            "| 에폭 134 |  반복 1 / 2 | 시간 0[s] | 손실 1.74\n",
            "| 에폭 135 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
            "| 에폭 136 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
            "| 에폭 137 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
            "| 에폭 138 |  반복 1 / 2 | 시간 0[s] | 손실 1.75\n",
            "| 에폭 139 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
            "| 에폭 140 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
            "| 에폭 141 |  반복 1 / 2 | 시간 0[s] | 손실 1.72\n",
            "| 에폭 142 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
            "| 에폭 143 |  반복 1 / 2 | 시간 0[s] | 손실 1.71\n",
            "| 에폭 144 |  반복 1 / 2 | 시간 0[s] | 손실 1.72\n",
            "| 에폭 145 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
            "| 에폭 146 |  반복 1 / 2 | 시간 0[s] | 손실 1.70\n",
            "| 에폭 147 |  반복 1 / 2 | 시간 0[s] | 손실 1.70\n",
            "| 에폭 148 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
            "| 에폭 149 |  반복 1 / 2 | 시간 0[s] | 손실 1.69\n",
            "| 에폭 150 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
            "| 에폭 151 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
            "| 에폭 152 |  반복 1 / 2 | 시간 0[s] | 손실 1.69\n",
            "| 에폭 153 |  반복 1 / 2 | 시간 0[s] | 손실 1.72\n",
            "| 에폭 154 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
            "| 에폭 155 |  반복 1 / 2 | 시간 0[s] | 손실 1.63\n",
            "| 에폭 156 |  반복 1 / 2 | 시간 0[s] | 손실 1.74\n",
            "| 에폭 157 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
            "| 에폭 158 |  반복 1 / 2 | 시간 0[s] | 손실 1.67\n",
            "| 에폭 159 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
            "| 에폭 160 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
            "| 에폭 161 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
            "| 에폭 162 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
            "| 에폭 163 |  반복 1 / 2 | 시간 0[s] | 손실 1.64\n",
            "| 에폭 164 |  반복 1 / 2 | 시간 0[s] | 손실 1.63\n",
            "| 에폭 165 |  반복 1 / 2 | 시간 0[s] | 손실 1.58\n",
            "| 에폭 166 |  반복 1 / 2 | 시간 0[s] | 손실 1.69\n",
            "| 에폭 167 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
            "| 에폭 168 |  반복 1 / 2 | 시간 0[s] | 손실 1.54\n",
            "| 에폭 169 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
            "| 에폭 170 |  반복 1 / 2 | 시간 0[s] | 손실 1.55\n",
            "| 에폭 171 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
            "| 에폭 172 |  반복 1 / 2 | 시간 0[s] | 손실 1.55\n",
            "| 에폭 173 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
            "| 에폭 174 |  반복 1 / 2 | 시간 0[s] | 손실 1.54\n",
            "| 에폭 175 |  반복 1 / 2 | 시간 0[s] | 손실 1.64\n",
            "| 에폭 176 |  반복 1 / 2 | 시간 0[s] | 손실 1.58\n",
            "| 에폭 177 |  반복 1 / 2 | 시간 0[s] | 손실 1.54\n",
            "| 에폭 178 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
            "| 에폭 179 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
            "| 에폭 180 |  반복 1 / 2 | 시간 0[s] | 손실 1.57\n",
            "| 에폭 181 |  반복 1 / 2 | 시간 0[s] | 손실 1.55\n",
            "| 에폭 182 |  반복 1 / 2 | 시간 0[s] | 손실 1.57\n",
            "| 에폭 183 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
            "| 에폭 184 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
            "| 에폭 185 |  반복 1 / 2 | 시간 0[s] | 손실 1.55\n",
            "| 에폭 186 |  반복 1 / 2 | 시간 0[s] | 손실 1.46\n",
            "| 에폭 187 |  반복 1 / 2 | 시간 0[s] | 손실 1.58\n",
            "| 에폭 188 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
            "| 에폭 189 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
            "| 에폭 190 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
            "| 에폭 191 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
            "| 에폭 192 |  반복 1 / 2 | 시간 0[s] | 손실 1.50\n",
            "| 에폭 193 |  반복 1 / 2 | 시간 0[s] | 손실 1.47\n",
            "| 에폭 194 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
            "| 에폭 195 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
            "| 에폭 196 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
            "| 에폭 197 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
            "| 에폭 198 |  반복 1 / 2 | 시간 0[s] | 손실 1.43\n",
            "| 에폭 199 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
            "| 에폭 200 |  반복 1 / 2 | 시간 0[s] | 손실 1.51\n",
            "| 에폭 201 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
            "| 에폭 202 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
            "| 에폭 203 |  반복 1 / 2 | 시간 0[s] | 손실 1.46\n",
            "| 에폭 204 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
            "| 에폭 205 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
            "| 에폭 206 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
            "| 에폭 207 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
            "| 에폭 208 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
            "| 에폭 209 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
            "| 에폭 210 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
            "| 에폭 211 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
            "| 에폭 212 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
            "| 에폭 213 |  반복 1 / 2 | 시간 0[s] | 손실 1.33\n",
            "| 에폭 214 |  반복 1 / 2 | 시간 0[s] | 손실 1.40\n",
            "| 에폭 215 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
            "| 에폭 216 |  반복 1 / 2 | 시간 0[s] | 손실 1.31\n",
            "| 에폭 217 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
            "| 에폭 218 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
            "| 에폭 219 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
            "| 에폭 220 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
            "| 에폭 221 |  반복 1 / 2 | 시간 0[s] | 손실 1.29\n",
            "| 에폭 222 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
            "| 에폭 223 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
            "| 에폭 224 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
            "| 에폭 225 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
            "| 에폭 226 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
            "| 에폭 227 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
            "| 에폭 228 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
            "| 에폭 229 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
            "| 에폭 230 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
            "| 에폭 231 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
            "| 에폭 232 |  반복 1 / 2 | 시간 0[s] | 손실 1.33\n",
            "| 에폭 233 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
            "| 에폭 234 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
            "| 에폭 235 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
            "| 에폭 236 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
            "| 에폭 237 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 238 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
            "| 에폭 239 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
            "| 에폭 240 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
            "| 에폭 241 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
            "| 에폭 242 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 243 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
            "| 에폭 244 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
            "| 에폭 245 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
            "| 에폭 246 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 247 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
            "| 에폭 248 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
            "| 에폭 249 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
            "| 에폭 250 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 251 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 252 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 253 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 254 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
            "| 에폭 255 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
            "| 에폭 256 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
            "| 에폭 257 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
            "| 에폭 258 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 259 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 260 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 261 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 262 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
            "| 에폭 263 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 264 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 265 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 266 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 267 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 268 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 269 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 270 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
            "| 에폭 271 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 272 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 273 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 274 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 275 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 276 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 277 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
            "| 에폭 278 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
            "| 에폭 279 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 280 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 281 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 282 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 283 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 284 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 285 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 286 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 287 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 288 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
            "| 에폭 289 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 290 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 291 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 292 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 293 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 294 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 295 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 296 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 297 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 298 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 299 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 300 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 301 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 302 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 303 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 304 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 305 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 306 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 307 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 308 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 309 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 310 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 311 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 312 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 313 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 314 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 315 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
            "| 에폭 316 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 317 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 318 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 319 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 320 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 321 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 322 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 323 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 324 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
            "| 에폭 325 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 326 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 327 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 328 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
            "| 에폭 329 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 330 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 331 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 332 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 333 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 334 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 335 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 336 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
            "| 에폭 337 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 338 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 339 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 340 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 341 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 342 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 343 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 344 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 345 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 346 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 347 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 348 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 349 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 350 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 351 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 352 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 353 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 354 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 355 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 356 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 357 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 358 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 359 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 360 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 361 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 362 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 363 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 364 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 365 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 366 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 367 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 368 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 369 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 370 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 371 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 372 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 373 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 374 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 375 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 376 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 377 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 378 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 379 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 380 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 381 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 382 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 383 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 384 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 385 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 386 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 387 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 388 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 389 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 390 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 391 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 392 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 393 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 394 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 395 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 396 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 397 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 398 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 399 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 400 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 401 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 402 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 403 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 404 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 405 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 406 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 407 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 408 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 409 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 410 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 411 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 412 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 413 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 414 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 415 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 416 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 417 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 418 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 419 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 420 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 421 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 422 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 423 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 424 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 425 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 426 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 427 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 428 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
            "| 에폭 429 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 430 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 431 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 432 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 433 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 434 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 435 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 436 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 437 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 438 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 439 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 440 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 441 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 442 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 443 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 444 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
            "| 에폭 445 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 446 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 447 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 448 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 449 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 450 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 451 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 452 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 453 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 454 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 455 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 456 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 457 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 458 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 459 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 460 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
            "| 에폭 461 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 462 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
            "| 에폭 463 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 464 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 465 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 466 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
            "| 에폭 467 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
            "| 에폭 468 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 469 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 470 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 471 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
            "| 에폭 472 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 473 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
            "| 에폭 474 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 475 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 476 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 477 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 478 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
            "| 에폭 479 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
            "| 에폭 480 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 481 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 482 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
            "| 에폭 483 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 484 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
            "| 에폭 485 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
            "| 에폭 486 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 487 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
            "| 에폭 488 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
            "| 에폭 489 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 490 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
            "| 에폭 491 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
            "| 에폭 492 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
            "| 에폭 493 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
            "| 에폭 494 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
            "| 에폭 495 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 496 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
            "| 에폭 497 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 498 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 499 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
            "| 에폭 500 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 501 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
            "| 에폭 502 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
            "| 에폭 503 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
            "| 에폭 504 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
            "| 에폭 505 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 506 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
            "| 에폭 507 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 508 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
            "| 에폭 509 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
            "| 에폭 510 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
            "| 에폭 511 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 512 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
            "| 에폭 513 |  반복 1 / 2 | 시간 0[s] | 손실 0.29\n",
            "| 에폭 514 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 515 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
            "| 에폭 516 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 517 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 518 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
            "| 에폭 519 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
            "| 에폭 520 |  반복 1 / 2 | 시간 0[s] | 손실 0.31\n",
            "| 에폭 521 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
            "| 에폭 522 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
            "| 에폭 523 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 524 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
            "| 에폭 525 |  반복 1 / 2 | 시간 0[s] | 손실 0.31\n",
            "| 에폭 526 |  반복 1 / 2 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 527 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
            "| 에폭 528 |  반복 1 / 2 | 시간 0[s] | 손실 0.31\n",
            "| 에폭 529 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
            "| 에폭 530 |  반복 1 / 2 | 시간 0[s] | 손실 0.27\n",
            "| 에폭 531 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 532 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 533 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 534 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
            "| 에폭 535 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 536 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
            "| 에폭 537 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 538 |  반복 1 / 2 | 시간 0[s] | 손실 0.29\n",
            "| 에폭 539 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 540 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 541 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 542 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
            "| 에폭 543 |  반복 1 / 2 | 시간 0[s] | 손실 0.29\n",
            "| 에폭 544 |  반복 1 / 2 | 시간 0[s] | 손실 0.31\n",
            "| 에폭 545 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 546 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
            "| 에폭 547 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 548 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 549 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 550 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 551 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
            "| 에폭 552 |  반복 1 / 2 | 시간 0[s] | 손실 0.31\n",
            "| 에폭 553 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
            "| 에폭 554 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
            "| 에폭 555 |  반복 1 / 2 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 556 |  반복 1 / 2 | 시간 0[s] | 손실 0.31\n",
            "| 에폭 557 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
            "| 에폭 558 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 559 |  반복 1 / 2 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 560 |  반복 1 / 2 | 시간 0[s] | 손실 0.27\n",
            "| 에폭 561 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
            "| 에폭 562 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
            "| 에폭 563 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 564 |  반복 1 / 2 | 시간 0[s] | 손실 0.31\n",
            "| 에폭 565 |  반복 1 / 2 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 566 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 567 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 568 |  반복 1 / 2 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 569 |  반복 1 / 2 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 570 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 571 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 572 |  반복 1 / 2 | 시간 0[s] | 손실 0.24\n",
            "| 에폭 573 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 574 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 575 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 576 |  반복 1 / 2 | 시간 0[s] | 손실 0.24\n",
            "| 에폭 577 |  반복 1 / 2 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 578 |  반복 1 / 2 | 시간 0[s] | 손실 0.24\n",
            "| 에폭 579 |  반복 1 / 2 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 580 |  반복 1 / 2 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 581 |  반복 1 / 2 | 시간 0[s] | 손실 0.31\n",
            "| 에폭 582 |  반복 1 / 2 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 583 |  반복 1 / 2 | 시간 0[s] | 손실 0.24\n",
            "| 에폭 584 |  반복 1 / 2 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 585 |  반복 1 / 2 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 586 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
            "| 에폭 587 |  반복 1 / 2 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 588 |  반복 1 / 2 | 시간 0[s] | 손실 0.27\n",
            "| 에폭 589 |  반복 1 / 2 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 590 |  반복 1 / 2 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 591 |  반복 1 / 2 | 시간 0[s] | 손실 0.27\n",
            "| 에폭 592 |  반복 1 / 2 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 593 |  반복 1 / 2 | 시간 0[s] | 손실 0.27\n",
            "| 에폭 594 |  반복 1 / 2 | 시간 0[s] | 손실 0.24\n",
            "| 에폭 595 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 596 |  반복 1 / 2 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 597 |  반복 1 / 2 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 598 |  반복 1 / 2 | 시간 0[s] | 손실 0.24\n",
            "| 에폭 599 |  반복 1 / 2 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 600 |  반복 1 / 2 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 601 |  반복 1 / 2 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 602 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 603 |  반복 1 / 2 | 시간 0[s] | 손실 0.24\n",
            "| 에폭 604 |  반복 1 / 2 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 605 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 606 |  반복 1 / 2 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 607 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 608 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
            "| 에폭 609 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 610 |  반복 1 / 2 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 611 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
            "| 에폭 612 |  반복 1 / 2 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 613 |  반복 1 / 2 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 614 |  반복 1 / 2 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 615 |  반복 1 / 2 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 616 |  반복 1 / 2 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 617 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 618 |  반복 1 / 2 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 619 |  반복 1 / 2 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 620 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
            "| 에폭 621 |  반복 1 / 2 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 622 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 623 |  반복 1 / 2 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 624 |  반복 1 / 2 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 625 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 626 |  반복 1 / 2 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 627 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 628 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 629 |  반복 1 / 2 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 630 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 631 |  반복 1 / 2 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 632 |  반복 1 / 2 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 633 |  반복 1 / 2 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 634 |  반복 1 / 2 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 635 |  반복 1 / 2 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 636 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 637 |  반복 1 / 2 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 638 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 639 |  반복 1 / 2 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 640 |  반복 1 / 2 | 시간 0[s] | 손실 0.24\n",
            "| 에폭 641 |  반복 1 / 2 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 642 |  반복 1 / 2 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 643 |  반복 1 / 2 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 644 |  반복 1 / 2 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 645 |  반복 1 / 2 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 646 |  반복 1 / 2 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 647 |  반복 1 / 2 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 648 |  반복 1 / 2 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 649 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 650 |  반복 1 / 2 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 651 |  반복 1 / 2 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 652 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 653 |  반복 1 / 2 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 654 |  반복 1 / 2 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 655 |  반복 1 / 2 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 656 |  반복 1 / 2 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 657 |  반복 1 / 2 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 658 |  반복 1 / 2 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 659 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 660 |  반복 1 / 2 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 661 |  반복 1 / 2 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 662 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 663 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 664 |  반복 1 / 2 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 665 |  반복 1 / 2 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 666 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 667 |  반복 1 / 2 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 668 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 669 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 670 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 671 |  반복 1 / 2 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 672 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 673 |  반복 1 / 2 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 674 |  반복 1 / 2 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 675 |  반복 1 / 2 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 676 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 677 |  반복 1 / 2 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 678 |  반복 1 / 2 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 679 |  반복 1 / 2 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 680 |  반복 1 / 2 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 681 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 682 |  반복 1 / 2 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 683 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 684 |  반복 1 / 2 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 685 |  반복 1 / 2 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 686 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 687 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 688 |  반복 1 / 2 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 689 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 690 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 691 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 692 |  반복 1 / 2 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 693 |  반복 1 / 2 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 694 |  반복 1 / 2 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 695 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 696 |  반복 1 / 2 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 697 |  반복 1 / 2 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 698 |  반복 1 / 2 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 699 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 700 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 701 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 702 |  반복 1 / 2 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 703 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 704 |  반복 1 / 2 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 705 |  반복 1 / 2 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 706 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 707 |  반복 1 / 2 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 708 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 709 |  반복 1 / 2 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 710 |  반복 1 / 2 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 711 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 712 |  반복 1 / 2 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 713 |  반복 1 / 2 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 714 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 715 |  반복 1 / 2 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 716 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 717 |  반복 1 / 2 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 718 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 719 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 720 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 721 |  반복 1 / 2 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 722 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 723 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 724 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 725 |  반복 1 / 2 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 726 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 727 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 728 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 729 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 730 |  반복 1 / 2 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 731 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 732 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 733 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 734 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 735 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 736 |  반복 1 / 2 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 737 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 738 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 739 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 740 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 741 |  반복 1 / 2 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 742 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 743 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 744 |  반복 1 / 2 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 745 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 746 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 747 |  반복 1 / 2 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 748 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 749 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 750 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 751 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 752 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 753 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 754 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 755 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 756 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 757 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 758 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 759 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 760 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 761 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 762 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 763 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 764 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 765 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 766 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 767 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 768 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 769 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 770 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 771 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 772 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 773 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 774 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 775 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 776 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 777 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 778 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 779 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 780 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 781 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 782 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 783 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 784 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 785 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 786 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 787 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 788 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 789 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 790 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 791 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 792 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 793 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 794 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 795 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 796 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 797 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 798 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 799 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 800 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 801 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 802 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 803 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 804 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 805 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 806 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 807 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 808 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 809 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 810 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 811 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 812 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 813 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 814 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 815 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 816 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 817 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 818 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 819 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 820 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 821 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 822 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 823 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 824 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 825 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 826 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 827 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 828 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 829 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 830 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 831 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 832 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 833 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 834 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 835 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 836 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 837 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 838 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 839 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 840 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 841 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 842 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 843 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 844 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 845 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 846 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 847 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 848 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 849 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 850 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 851 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 852 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 853 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 854 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 855 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 856 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 857 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 858 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 859 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 860 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 861 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 862 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 863 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 864 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 865 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 866 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 867 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 868 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 869 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 870 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 871 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 872 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 873 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 874 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 875 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 876 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 877 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 878 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 879 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 880 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 881 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 882 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 883 |  반복 1 / 2 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 884 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 885 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 886 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 887 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 888 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 889 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 890 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 891 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 892 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 893 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 894 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 895 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 896 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 897 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 898 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 899 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 900 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 901 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 902 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 903 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 904 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 905 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 906 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 907 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 908 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 909 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 910 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 911 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 912 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 913 |  반복 1 / 2 | 시간 0[s] | 손실 0.09\n",
            "| 에폭 914 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 915 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 916 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 917 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 918 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 919 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 920 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 921 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 922 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 923 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 924 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 925 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 926 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 927 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 928 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 929 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 930 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 931 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 932 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 933 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 934 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 935 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 936 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 937 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 938 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 939 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 940 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 941 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 942 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 943 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 944 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 945 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 946 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 947 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 948 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 949 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 950 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 951 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 952 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 953 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 954 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 955 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 956 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 957 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 958 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 959 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 960 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 961 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 962 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 963 |  반복 1 / 2 | 시간 0[s] | 손실 0.05\n",
            "| 에폭 964 |  반복 1 / 2 | 시간 0[s] | 손실 0.08\n",
            "| 에폭 965 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 966 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 967 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 968 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 969 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 970 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 971 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 972 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 973 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 974 |  반복 1 / 2 | 시간 0[s] | 손실 0.05\n",
            "| 에폭 975 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 976 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 977 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 978 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 979 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 980 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 981 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 982 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 983 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 984 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 985 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 986 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 987 |  반복 1 / 2 | 시간 0[s] | 손실 0.05\n",
            "| 에폭 988 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 989 |  반복 1 / 2 | 시간 0[s] | 손실 0.05\n",
            "| 에폭 990 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 991 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 992 |  반복 1 / 2 | 시간 0[s] | 손실 0.07\n",
            "| 에폭 993 |  반복 1 / 2 | 시간 0[s] | 손실 0.05\n",
            "| 에폭 994 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 995 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 996 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 997 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 998 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 999 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n",
            "| 에폭 1000 |  반복 1 / 2 | 시간 0[s] | 손실 0.06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48152 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48373 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49552 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49892 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48152 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48373 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49552 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49892 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyOsJjWGfrkT",
        "outputId": "82c5f0dd-a3c6-4148-e88b-7b6e35495437"
      },
      "source": [
        "word_vecs = model.word_vecs\r\n",
        "\r\n",
        "for word_id, word in id_to_word.items() :\r\n",
        "  print(word, word_vecs[word_id]) # 대응하는 단어 ID의 분산 표현"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "you [-1.2783585  1.0661008  1.4041533  0.9247976 -0.7817244]\n",
            "say [ 1.2863058  1.2244338  1.2751263 -1.0192852  1.2517244]\n",
            "goodbye [-0.61291796  1.4156067  -0.02064987  1.4508197  -1.4567227 ]\n",
            "and [ 0.31690037 -0.9133648   1.5060276  -1.4435369   0.39484617]\n",
            "i [ 1.445618    1.3924631  -1.5673728  -0.35307717 -0.23363668]\n",
            "san [-1.4123195  -1.4243504  -0.08328641 -0.6086579  -1.4148792 ]\n",
            "hello [ 0.9752423   0.95640856 -1.1407146  -1.3155775   1.3172697 ]\n",
            ". [-1.0338564 -1.121315  -1.398268   1.3216097 -1.0197542]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4XZZy5Ntthh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}