{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "학습관련기술들(1)_매개변수갱신.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNuc+zFQob/scguBZmU1p8Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeaeunJi/deep_learning-/blob/main/%ED%95%99%EC%8A%B5%EA%B4%80%EB%A0%A8%EA%B8%B0%EC%88%A0%EB%93%A4(1)_%EB%A7%A4%EA%B0%9C%EB%B3%80%EC%88%98%EA%B0%B1%EC%8B%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1_e3zUbtKtq"
      },
      "source": [
        "## 매개변수 갱신\r\n",
        "- 신경망의 목적 : 손실 함수의 값을 가능한 한 낮추는 매개변수 찾기\r\n",
        "\r\n",
        "   ==> 최적화(optimization)\r\n",
        "\r\n",
        "- 확률적 경사 하강법(SGD) : 최적의 매개변수 값을 찾는 방법 중 하나로 매개변수의 기울기(미분)을 통해서 기울어진 방향으로 매개변수 값을 갱신을 반복함으로써 최적의 매개변수 값을 찾고자 함\r\n",
        "\r\n",
        "- SGD의 단점과 다른 최적화 기법을 배우고자 함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_JUODfIuf-Z"
      },
      "source": [
        "### 확률적 경사 하강법(SGD)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLesuy3fXmNS"
      },
      "source": [
        "class SGD :\r\n",
        "  def __init__(self, lr = 0.01) :\r\n",
        "    self.lr = lr\r\n",
        "  \r\n",
        "  def update(self, params, grads) :\r\n",
        "    for key in params.keys() :\r\n",
        "      params[key] -=  self.lr * grads[key] # params['W1'] : 가중치, grads['W1'] : 기울기\r\n",
        "\r\n",
        "# SGD 클래스를 사용한 신경망 매개변수의 진행 예\r\n",
        "# network = TwoLayerNet(매개변수)\r\n",
        "# optimizer = SGD()\r\n",
        "\r\n",
        "# for i in range(1000) :\r\n",
        "#   x_batch, y_batch = get_mini_batch(...) \r\n",
        "#   grads = network.gradient(x_batch, t_batch)\r\n",
        "#   params = network.params\r\n",
        "#   optimizer.update(params, grads)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CCnITLJzg8n"
      },
      "source": [
        "### SGD 단점\r\n",
        "- 단순하고 구현이 쉽지만 경우에 따라 비효율적일 때가 존재함\r\n",
        "  - 비등방성(anisotropy) 함수(방향에 따라 기울기가 달리지는 함수)에서 매개변수의 기울기 탐색 경로가 비효율적(지그재그로 이동)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqKF9zn0rDrf"
      },
      "source": [
        "### 모멘텀(Momentum)\r\n",
        "-  '운동량'을 의미하는 단어"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG1o1CI8zgRJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}