{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "학습관련기술들(1)_매개변수갱신.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBm9yPfpyAkyOhHSZHvIDR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeaeunJi/deep_learning-/blob/main/%ED%95%99%EC%8A%B5%EA%B4%80%EB%A0%A8%EA%B8%B0%EC%88%A0%EB%93%A4(1)_%EB%A7%A4%EA%B0%9C%EB%B3%80%EC%88%98%EA%B0%B1%EC%8B%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1_e3zUbtKtq"
      },
      "source": [
        "## 매개변수 갱신\r\n",
        "- 신경망의 목적 : 손실 함수의 값을 가능한 한 낮추는 매개변수 찾기\r\n",
        "\r\n",
        "   ==> 최적화(optimization)\r\n",
        "\r\n",
        "- 확률적 경사 하강법(SGD) : 최적의 매개변수 값을 찾는 방법 중 하나로 매개변수의 기울기(미분)을 통해서 기울어진 방향으로 매개변수 값을 갱신을 반복함으로써 최적의 매개변수 값을 찾고자 함\r\n",
        "\r\n",
        "- SGD의 단점과 다른 최적화 기법을 배우고자 함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_JUODfIuf-Z"
      },
      "source": [
        "### 확률적 경사 하강법(SGD)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLesuy3fXmNS"
      },
      "source": [
        "class SGD :\r\n",
        "  def __init__(self, lr = 0.01) :\r\n",
        "    self.lr = lr\r\n",
        "  \r\n",
        "  def update(self, params, grads) :\r\n",
        "    for key in params.keys() :\r\n",
        "      params[key] -=  self.lr * grads[key] # params['W1'] : 가중치, grads['W1'] : 기울기\r\n",
        "\r\n",
        "# SGD 클래스를 사용한 신경망 매개변수의 진행 예\r\n",
        "# network = TwoLayerNet(매개변수)\r\n",
        "# optimizer = SGD()\r\n",
        "\r\n",
        "# for i in range(1000) :\r\n",
        "#   x_batch, y_batch = get_mini_batch(...) \r\n",
        "#   grads = network.gradient(x_batch, t_batch)\r\n",
        "#   params = network.params\r\n",
        "#   optimizer.update(params, grads)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CCnITLJzg8n"
      },
      "source": [
        "### SGD 단점\r\n",
        "- 단순하고 구현이 쉽지만 경우에 따라 비효율적일 때가 존재함\r\n",
        "  - 비등방성(anisotropy) 함수(방향에 따라 기울기가 달리지는 함수)에서 매개변수의 기울기 탐색 경로가 비효율적(지그재그로 이동)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqKF9zn0rDrf"
      },
      "source": [
        "### 모멘텀(Momentum)\r\n",
        "-  '운동량'을 의미하는 단어\r\n",
        "- 공이 그릇의 곡면(기울기)를 따라 구르듯 움직이듯이 최적화하는 방법\r\n",
        "- SGD와 비교하면 최적화하는 경로의 지그재그 정도가 덜함. 그 이유는 x축의 힘은 아주 작지만 방향을 변하지 않아 한 방향으로 일정하게 가속하기 때문임. y축의 힘은 크지만 위아래로 번갈아 상충하여 속도가 안정적이지 않음\r\n",
        "- 속도(v) : av(물체가 아무런 힘을 받지 않을 때 서서히 하강시키는 역할) - 학습률*W(가중치)에 대한 손실 함수의 기울기\r\n",
        "- W(가중치) = W + v"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG1o1CI8zgRJ"
      },
      "source": [
        "class Momentum :\r\n",
        "  def __init__(self, lr=0.1, momentum=0.9) :\r\n",
        "    self.lr = lr\r\n",
        "    self.momentum = momentum\r\n",
        "    self.v = None # 물체의 속도. \r\n",
        "\r\n",
        "  def update(self, params, grads) :\r\n",
        "    if self.v is None :\r\n",
        "      self.v = {}  # 매개변수와 같은 구조의 데이터를 dict 변수로 저장\r\n",
        "      for key, val in params.items() :\r\n",
        "        self.v[key] = np.zeros_like(val)\r\n",
        "      \r\n",
        "    for key in params.keys() :\r\n",
        "      self.v[key] = self.momentum + self.v[key] - self.lr * grads[key]\r\n",
        "      params[key] += self.v[key]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g-WaUPh7AIt"
      },
      "source": [
        "### AdaGrad\r\n",
        "- 신경망 학습에서는 학습률 값이 중요한데, 학습률이 너무 작으면 학습 시간이 증가하게 되고 학습률이 너무 크면 발산하여 학습이 제대로 이뤄지지 않음\r\n",
        "\r\n",
        "- 학습률을 정하는 기술로는 '학습률 감소(learning rate decay)가 있음\r\n",
        "  - 학습을 진행하면서 학습률을 점차 줄여가는 방법으로 처음에는 크게 학습하다가 조금씩 작게 학습하도록 함\r\n",
        "  - 학습률을 서서히 낮추는 간단한 방법으로는 매개변수 전체의 학습률을 일괄적으로 낮추는 방법이 있는데, 이를 발전시킨 것이 AdaGrad임\r\n",
        "\r\n",
        "- AdaGrad는 각각의 매개변수에 맞는 값을 만들어줌. 즉, 개별 매개변수에 적응적으로(adaptive) 학습률을 조정하며 학습을 진행\r\n",
        "  - 매개변수의 원소 중에서 많이 갱신된 원소를 학습률이 낮아짐\r\n",
        "  - 과거의 기울기를 제곱하여 계속하여 더하므로 학습이 진행될 수록 학습 정도가 약해짐. \r\n",
        "  - 무한히 학습하다보면 갱신률이 0이되어 전혀 갱신되지 않게 됨. 이문제를 해결한 기법으로 RMSProp가 있으며 이는 먼 과거의 기울기는 잊고 새로운 기울기 정보를 크게 반영하는 것임. 이를 '지수이동평균(Exponential Moving Average, EMA)라 함. 과거 기울기의 반영 규모를 기하급수적으로 감소시킴"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TnnSyz79UCc"
      },
      "source": [
        "class AdaGrad :\r\n",
        "  def __init__(self, lr = 0.01) :\r\n",
        "    self.lr = lr\r\n",
        "    self.h = None\r\n",
        "\r\n",
        "  def update(self, params, grads) :\r\n",
        "    if self.h is None :\r\n",
        "      self.h = {}\r\n",
        "\r\n",
        "      for key, val in  params.items() :\r\n",
        "        self.h[key] = np.zeros_like(val)\r\n",
        "\r\n",
        "      for key in params.keys() :\r\n",
        "        self.h[key] += grads[key] * grads[key]\r\n",
        "        params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key] + 1e-7)) # self.h[key]값이 0이 되더라도 0으로 나누지 않도록 하기 위해 아주 작은 값을 더함"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm4wa8rr-QYm"
      },
      "source": [
        "### Adam\r\n",
        "- 마치 모멘텀과 AdaGrad를 융합한 듯 보이기도 하는 방법으로 매개 변수 공간을 효율적으로 탐색 및 하이퍼파라미터의 '편향 보정'이 진행되는 것이 특징임\r\n",
        "- 그릇 바닥을 구르듯 움직이며 최적화를 진행. 모멘텀과 비슷한 패턴이지만 그보다는 공의 좌우 흔들림이 적음.\r\n",
        "- 논문에 따르면 Adam의 하이퍼파라미터는 학습률, 일차 모멘텀용 계수 베타1, 이차 모멘텀용 계수 베타2 3가지이다. 기본 설정값은 베타1 = 0.9, 베타2 = 0.999d이면 많은 경우 좋은 결과를 얻을 수 있다고 함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arv3FjMd_a1P"
      },
      "source": [
        "# 아래 코드는 https://github.com/WegraLee/deep-learning-from-scratch/blob/master/common/optimizer.py에서 가져온 소스 코드이다\r\n",
        "class RMSprop:\r\n",
        "\r\n",
        "    \"\"\"RMSprop\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, lr=0.01, decay_rate = 0.99):\r\n",
        "        self.lr = lr\r\n",
        "        self.decay_rate = decay_rate\r\n",
        "        self.h = None\r\n",
        "        \r\n",
        "    def update(self, params, grads):\r\n",
        "        if self.h is None:\r\n",
        "            self.h = {}\r\n",
        "            for key, val in params.items():\r\n",
        "                self.h[key] = np.zeros_like(val)\r\n",
        "            \r\n",
        "        for key in params.keys():\r\n",
        "            self.h[key] *= self.decay_rate\r\n",
        "            self.h[key] += (1 - self.decay_rate) * grads[key] * grads[key]\r\n",
        "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\r\n",
        "\r\n",
        "\r\n",
        "class Adam:\r\n",
        "\r\n",
        "    \"\"\"Adam (http://arxiv.org/abs/1412.6980v8)\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\r\n",
        "        self.lr = lr\r\n",
        "        self.beta1 = beta1\r\n",
        "        self.beta2 = beta2\r\n",
        "        self.iter = 0\r\n",
        "        self.m = None\r\n",
        "        self.v = None\r\n",
        "        \r\n",
        "    def update(self, params, grads):\r\n",
        "        if self.m is None:\r\n",
        "            self.m, self.v = {}, {}\r\n",
        "            for key, val in params.items():\r\n",
        "                self.m[key] = np.zeros_like(val)\r\n",
        "                self.v[key] = np.zeros_like(val)\r\n",
        "        \r\n",
        "        self.iter += 1\r\n",
        "        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)         \r\n",
        "        \r\n",
        "        for key in params.keys():\r\n",
        "            #self.m[key] = self.beta1*self.m[key] + (1-self.beta1)*grads[key]\r\n",
        "            #self.v[key] = self.beta2*self.v[key] + (1-self.beta2)*(grads[key]**2)\r\n",
        "            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])\r\n",
        "            self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])\r\n",
        "            \r\n",
        "            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)\r\n",
        "            \r\n",
        "            #unbias_m += (1 - self.beta1) * (grads[key] - self.m[key]) # correct bias\r\n",
        "            #unbisa_b += (1 - self.beta2) * (grads[key]*grads[key] - self.v[key]) # correct bias\r\n",
        "            #params[key] += self.lr * unbias_m / (np.sqrt(unbisa_b) + 1e-7)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXUnw745_-Zs"
      },
      "source": [
        "### 경우에 따라 이 4가지 기법이 좋은 결과를 낼 때가 다름. 하지만 일반적으로 SGD보다 다른 기법들이 빠르게 학습하고, 때로 최종 정확도도 높게 나타난다고 함.\r\n",
        "많은 연구에서 SGD를 사용하고 있음"
      ]
    }
  ]
}