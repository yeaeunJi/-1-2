{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "오차역전파법.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LraHsxEFN--E",
        "RM7BUCvDOP9F",
        "MJ7gVNJjPhge",
        "bXEEvrQVayJw",
        "q8YT6qpDL6AE"
      ],
      "authorship_tag": "ABX9TyN7ajxwPaE9N9kt0oB/j2SE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeaeunJi/deep_learning-/blob/main/%EC%98%A4%EC%B0%A8%EC%97%AD%EC%A0%84%ED%8C%8C%EB%B2%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyMH4wkQNfH0"
      },
      "source": [
        "- 오차역전파법(backpropagation)은 가중치 매개변수의 기울기를 효율적으로 계산할 수 있음\n",
        "- 오차역전파란 풀어서 설명하면 '오차를 역방향으로 전파하는 방법'이라고 할 수 있음\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LraHsxEFN--E"
      },
      "source": [
        "## 계산그래프(computational graph)\n",
        "- 계산그래프를 통해서 오차역전파에 대해 시각적으로 이해할 수 있음\n",
        "- 계산그래프란 계산 과정을 그래프로 나타낸 것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM7BUCvDOP9F"
      },
      "source": [
        "### 계산 그래프로 풀어보기\n",
        "- 슈퍼에서 1개에 100원인 사과 2개를 구매했을 때, 지불 금액은 얼마인가(단, 소비세가 10% 부과됨)\n",
        "- 슈퍼에서 한개에 100원인 사과 2개, 1개에 150원인 귤 3개를 구매했을 때, 지불 금액은 얼마인가(단, 소비세는 10% 부과됨)\n",
        "\n",
        "- 계산 그래프를 푸는 흐름\n",
        "  - 계산 그래프를 구성한 후 왼쪽에서 오른쪽으로 계산 진행(순전파)\n",
        "  \n",
        "  * 순전파 : 계산 그래프의 출발점에서 종착점으로의 전파\n",
        "  * 역전파 : 계산 그래프의 종착점에서 출발점으로 전파\n",
        "\n",
        "- 역전파는 미분을 계산할 때 중요한 역할을 수행함 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ7gVNJjPhge"
      },
      "source": [
        "### 국소적 계산\n",
        "- 계산 그래프의 특징 : 국소적 계산을 전파하여 최종 결과를 얻음\n",
        "\n",
        "* 국소적 : 자신과 직접 관계된 작은 범위\n",
        "\n",
        "  - 각 노드는 자신과 관련된 계산 외에는 관심x\n",
        "\n",
        "- 계산 그래프의 이점 \n",
        "  - 전체가 아무리 복잡해도 각 노드에서는 단순한 계산에 집중하여 문지를 단순화 가능 + 중간 계산 결과를 모두 보관할 수 있음\n",
        "  - 가장 중요한 부분은 역전파를 통해 미분을 효율적으로 계산 가능\n",
        "  (국소적 미분을 수행한 후 그 값을 왼쪽으로 전달)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXEEvrQVayJw"
      },
      "source": [
        "## 단순한 계층 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfGBqfiaN-X9"
      },
      "source": [
        "# 곱셈 계층 구현하기\n",
        "class MulLayer :\n",
        "  def __init__ (self) :\n",
        "    # 순전파시 입력 값을 유지하기 위해서 사용\n",
        "    self.x = None\n",
        "    self.y = None\n",
        "\n",
        "  def forward(self, x, y) :\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    out = x * y\n",
        "\n",
        "    return out\n",
        "  \n",
        "  def backward(self, dout) :\n",
        "    dx = dout * self.y # x와 y를 바꾼다\n",
        "    dy = dout * self.x \n",
        "\n",
        "    return dx, dy"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIDfz9PuPHy7",
        "outputId": "a0b976ea-7f59-49d7-f284-b4d0804bb6c9"
      },
      "source": [
        "apple = 100\n",
        "apple_num = 2\n",
        "tax = 1.1\n",
        "\n",
        "# 계층들\n",
        "mul_apple_layer = MulLayer()\n",
        "mul_tax_layer = MulLayer()\n",
        "\n",
        "# 순전파\n",
        "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
        "price = mul_tax_layer.forward(apple_price, tax)\n",
        "\n",
        "print(price)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "220.00000000000003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPtugaXYPf8_",
        "outputId": "4a4d1a20-a2c2-4de7-938f-2fdc83096bc9"
      },
      "source": [
        "# 역전파를 통해  각 변수에 대한 미분 값 구하기\n",
        "dprice = 1\n",
        "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
        "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
        "\n",
        "print(dapple_price, dapple_num, dtax)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1 110.00000000000001 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsTriLnrPzcJ"
      },
      "source": [
        "# 덧셈 계층 구현하기\n",
        "class AddLayer :\n",
        "  def __init__(self) :\n",
        "    pass\n",
        "\n",
        "  def forward(self, x, y) :\n",
        "    out = x+y\n",
        "    return out\n",
        "  \n",
        "  def backward(self, dout) :\n",
        "    dx = dout * 1\n",
        "    dy = dout * 1\n",
        "    return dx, dy "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff991q-z1VRw",
        "outputId": "bc43d65a-d054-432e-9aaa-6ad72bda619f"
      },
      "source": [
        "# 위에서 구현한 덧셈 계층과 곱셈 계층을 통해 사과 2개와 귤 3개를 사는 상황을 구현\n",
        "apple = 100\n",
        "apple_num = 2 \n",
        "orange = 15\n",
        "orange_num = 3\n",
        "tax = 1.1\n",
        "\n",
        "# 계층들\n",
        "mul_apple_layer = MulLayer()\n",
        "mul_orange_layer = MulLayer()\n",
        "add_apple_orange_layer = AddLayer()\n",
        "mul_tax_layer = MulLayer()\n",
        "\n",
        "# 순전파\n",
        "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
        "orange_price = mul_orange_layer.forward(orange, orange_num)\n",
        "all_price = add_apple_orange_layer.forward(apple_price, orange_price)\n",
        "price = mul_tax_layer.forward(all_price, tax)\n",
        "\n",
        "# 역전파\n",
        "dprice  = 1\n",
        "dall_price, dtax = mul_tax_layer.backward(dprice)\n",
        "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)\n",
        "dorange, dorange_num = mul_orange_layer.backward(dorange_price)\n",
        "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
        "\n",
        "print(price)\n",
        "print(dapple_num, dapple, dorange, dorange_num, dtax)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "269.5\n",
            "110.00000000000001 2.2 3.3000000000000003 16.5 245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1Foe7t93H3B"
      },
      "source": [
        "## 활성화 함수 계층 구현\n",
        "### ReLU 계층\n",
        "- 순전파 때 입력 x가 0보다 크면 역전파는 상류의 값을 그대로 하류로 보내고,\n",
        "순전파 때 입력 x가 0보다 작거나 같으면 역전파는 그 값을 하류로 신호 보내지 않음(0을 보냄)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR2QTQdv21Hd"
      },
      "source": [
        "## ReLu 계층 구현\n",
        "class Relu :\n",
        "  def __init__(self) :\n",
        "    self.mask = None\n",
        "\n",
        "  def forward(self, x) :\n",
        "    self.mask = ( x <= 0)\n",
        "    out = x.copy()\n",
        "    out[self.mask] = 0\n",
        "    return out\n",
        "    \n",
        "  def backward(self, dout) :\n",
        "    dout[self.mask] = 0\n",
        "    dx = dout\n",
        "    return dx"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtokS6d05wtw",
        "outputId": "c70a2621-b4ba-4379-a960-1abf1aa57233"
      },
      "source": [
        "import numpy as np\n",
        "x = np.array([[1.0, -0.5], [-2.0, 3.0]])\n",
        "print(x)\n",
        "\n",
        "mask = (x <= 0 )\n",
        "print(mask)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.  -0.5]\n",
            " [-2.   3. ]]\n",
            "[[False  True]\n",
            " [ True False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAzNy5LH6NcX"
      },
      "source": [
        "### Sigmoid 계층\n",
        "- 순전파의 출력 y만으로도 역전파를 계산할 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sbuLAPZ563p"
      },
      "source": [
        "class Sigmoid :\n",
        "  def __init__(self) : \n",
        "    self.out = None\n",
        "  \n",
        "  def forward(self, x ) :\n",
        "    out = 1 / (1+np.exp(-x))\n",
        "    self.out = out # 순전파의 출력을 보관 후 역전파 계산 시 사용\n",
        "    return out\n",
        "  \n",
        "  def backward(self, dout) :\n",
        "    dx = dout * (1.0 - self.out) * self.out\n",
        "    return dx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJPgGR8b8d8F"
      },
      "source": [
        "## Affine/Softmax 계층 구현\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PstxEWSO_9eN"
      },
      "source": [
        "class Affine :\n",
        "  def __init__(self, W, b) :\n",
        "    self.W = W\n",
        "    self.b = b\n",
        "    self.x = None\n",
        "    self.dW = None\n",
        "    self.db = None\n",
        "\n",
        "  def forward(self, x) :\n",
        "    self.x = x\n",
        "    # print(x)\n",
        "    out = np.dot(x, self.W) + self.b\n",
        "\n",
        "    return out\n",
        "  \n",
        "  def backward(self, dout) :\n",
        "    # print(dout)\n",
        "    dx = np.dot(dout, self.W.T)\n",
        "    self.dW = np.dot(self.x.T, dout)\n",
        "    self.db = np.sum(dout, axis = 0)\n",
        "\n",
        "    return dx\n",
        "  "
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaZ2xEqYQQkC"
      },
      "source": [
        "def softmax(x):\r\n",
        "    if x.ndim == 2:\r\n",
        "        x = x.T\r\n",
        "        x = x - np.max(x, axis=0)\r\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\r\n",
        "        return y.T \r\n",
        "\r\n",
        "    x = x - np.max(x) # 오버플로 대책\r\n",
        "    return np.exp(x) / np.sum(np.exp(x))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVQP1dh1S-Va"
      },
      "source": [
        "def cross_entropy_error(y, t):\r\n",
        "    if y.ndim == 1:\r\n",
        "        t = t.reshape(1, t.size)\r\n",
        "        y = y.reshape(1, y.size)\r\n",
        "        \r\n",
        "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\r\n",
        "    if t.size == y.size:\r\n",
        "        t = t.argmax(axis=1)\r\n",
        "             \r\n",
        "    batch_size = y.shape[0]\r\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qquxqGXoArTy"
      },
      "source": [
        "### Softmax-with-Loss 계층\n",
        "- 출력층에서 사용하는 소프트 맥스 함수(입력 값을 정규화(출력의 합이 1이됨)하여 출력)\n",
        "- 신경망 추론 시에는 softmax 계층이 필요없으나 신경망을 학습할 때에는 Softmax 계층이 필요\n",
        "- 소프트맥스 계층 + 손실 함수인 교차 엔트로피 오차도 포함한 계층을 구현해봄\n",
        "- 소프트맥스의 역전파는 소프트맥스의 출력값과 정답 레이블의 차분(오차)가 앞 계층에 전해지는 것\n",
        "- 회귀 출력층에서 사용하는 '항등함수'의 손실 함수로 '오차제곱합'을 이용하는 이유는 이를 사용하면 역전파의 결과가 출력값-정답인 차분으로 말끔히 떨어지기 때문"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YveQSnTbAlzz"
      },
      "source": [
        "class SoftmaxWithLoss :\n",
        "  def __init__(self):\n",
        "    self.loss = None # 손실\n",
        "    self.y = None # softmax의 출력\n",
        "    self.t = None # 정답레이블(원-핫 벡터)\n",
        "\n",
        "  def forward(self, x, t) :\n",
        "    self.t = t\n",
        "    self.y = softmax(x)\n",
        "    self.loss = cross_entropy_error(self.y, self.t)\n",
        "    return self.loss\n",
        "\n",
        "  def backward(self, dout = 1):\n",
        "    batch_size = self.t.shape[0]\n",
        "    dx = (self.y - self.t) / batch_size # 역전파 시 전파하는 값을 배치의 수로 나눠서 데이터 1개당 오차를 앞 계층에 전파함\n",
        "    return dx"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5PrTosFFUgU"
      },
      "source": [
        "## 오차역전파법 구현\r\n",
        "- 그동안 했던 것들을 조합하여 오차역전파 구현\r\n",
        "- 신경망 학습 전체 그림\r\n",
        "  - 전제 : 가중치와 편향을 훈련 데이터에 적응하도록 조정하는 학습 과정 존재\r\n",
        "  - 1. 미니배치 : 훈련 데이터 중 일부를 무작위 추출한 미니배치의 손실 함수 값을 줄이는 것이 목표\r\n",
        "  - 2. 기울기 산출 : 미니배치릐 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구함\r\n",
        "  - 3. 매개변수 갱신 : 가중치 매개변수를 기울기 방향으로 아주 조금 갱신\r\n",
        "  - 4. 1~3 반복"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4bNxsAMExrK"
      },
      "source": [
        "# 오차역전파법을 적용한 신경망은 수치 미분으로 구현한 것보다 효율적으로 기울기 산출 가능"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJRvDYH2F_1y"
      },
      "source": [
        "import numpy as np\r\n",
        "from collections import OrderedDict # 순서가 보장되는 dict\r\n",
        "\r\n",
        "def numerical_gradient(f, x):\r\n",
        "    h = 1e-4 # 0.0001\r\n",
        "    grad = np.zeros_like(x)\r\n",
        "    \r\n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\r\n",
        "    while not it.finished:\r\n",
        "        idx = it.multi_index\r\n",
        "        tmp_val = x[idx]\r\n",
        "        x[idx] = float(tmp_val) + h\r\n",
        "        fxh1 = f(x) # f(x+h)\r\n",
        "        \r\n",
        "        x[idx] = tmp_val - h \r\n",
        "        fxh2 = f(x) # f(x-h)\r\n",
        "        grad[idx] = (fxh1 - fxh2) / (2*h)\r\n",
        "        \r\n",
        "        x[idx] = tmp_val # 값 복원\r\n",
        "        it.iternext()   \r\n",
        "        \r\n",
        "    return grad\r\n",
        "\r\n",
        "class TwoLayerNet :\r\n",
        "  def __init__(self, input_size, hidden_size, output_size,\r\n",
        "               weight_init_std = 0.01) :\r\n",
        "    # 가중치 초기화\r\n",
        "    self.params = {}\r\n",
        "    self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\r\n",
        "    self.params['b1'] = np.zeros(hidden_size)\r\n",
        "    self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\r\n",
        "    self.params['b2'] = np.zeros(output_size)\r\n",
        "\r\n",
        "    # 계층 생성\r\n",
        "    self.layers = OrderedDict()\r\n",
        "    self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\r\n",
        "    self.layers['Relu1'] = Relu()\r\n",
        "    self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\r\n",
        "\r\n",
        "    self.lastLayer = SoftmaxWithLoss()\r\n",
        "  \r\n",
        "  def predict(self, x) :\r\n",
        "    for layer in self.layers.values() :\r\n",
        "      # print(layer)\r\n",
        "      x = layer.forward(x)\r\n",
        "    \r\n",
        "    return x\r\n",
        "\r\n",
        "  def loss(self, x, t) :\r\n",
        "    y = self.predict(x)\r\n",
        "    return self.lastLayer.forward(y, t)\r\n",
        "  \r\n",
        "  def accuracy(self, x, t) :\r\n",
        "    y = self.predict(x)\r\n",
        "    y = np.argmax(y, axis=1)\r\n",
        "    if t.ndim != 1 : t = np.argmax(t, axis=1)\r\n",
        "\r\n",
        "    accuracy = np.sum(y==t) / float(x.shape[0])\r\n",
        "    return accuracy\r\n",
        "\r\n",
        "  def numerical_gradient(self, x, t) :\r\n",
        "    loss_W = lambda W : self.loss(x,t)\r\n",
        "\r\n",
        "    grads = {}\r\n",
        "    grads['W1'] = numerical_gradient(loss_W , self.params['W1'])\r\n",
        "    grads['b1'] = numerical_gradient(loss_W , self.params['b1'])\r\n",
        "    grads['W2'] = numerical_gradient(loss_W , self.params['W2'])\r\n",
        "    grads['b2'] = numerical_gradient(loss_W , self.params['b2'])\r\n",
        "\r\n",
        "    return grads            \r\n",
        "  \r\n",
        "  def gradient(self, x, t) :\r\n",
        "    # 순전파\r\n",
        "    self.loss(x, t)\r\n",
        "\r\n",
        "    # 역전파\r\n",
        "    dout = 1\r\n",
        "    dout = self.lastLayer.backward(dout)\r\n",
        "\r\n",
        "    layers = list(self.layers.values()) # OrderedDict 객체이므로 입력한 순서가 저장되어 있음. 따라서 역전파 시에는\r\n",
        "                                        # 입력한 순서의 반대로 계층을 호출하면 처리가 됨\r\n",
        "    layers.reverse()\r\n",
        "    for layer in layers :\r\n",
        "      dout = layer.backward(dout)\r\n",
        "    \r\n",
        "    # 결과 저장\r\n",
        "    grads = {}\r\n",
        "    grads['W1'] = self.layers['Affine1'].dW\r\n",
        "    grads['b1'] = self.layers['Affine1'].db\r\n",
        "    grads['W2'] = self.layers['Affine2'].dW\r\n",
        "    grads['b2'] = self.layers['Affine2'].db\r\n",
        "\r\n",
        "    return grads\r\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8YT6qpDL6AE"
      },
      "source": [
        "### 오차역전파법으로 구한 기울기 검증\r\n",
        "- 기울기를 구하기 위해 수치미분을 사용하는 경우, 구현이 쉽지만 오차역전파를 사용하는 경우에는 구현 시 종종 실수가 발생할 수 있음\r\n",
        "  - 따라서, 수치 미분으로 구한 결과와 오차역전파로 구한 결과를 비교하여 검증.\r\n",
        "  이러한 것을 '기울기 확인(gradient check)'라고 함\r\n",
        "  - 두 가지 경우의 차가 0이 될 확률은 적음(컴퓨터가 할 수 있는 계산의 정밀도가 유한). 하지만 올바르게 구현되었다면 0에 아주 가까운 값이 될 것이므로 오차가 클 경우, 오차역전파법을 잘못 구현한 것인지 확인 필요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBSfSwMNMeJ-"
      },
      "source": [
        "# 각 가중치 차이의 절댓값을 구한 후, 그 절댓값들의 평균을 구하는 방식을 통해 검증 가능\r\n",
        "# 예시 코드\r\n",
        "for key in grad_numerical_keys() :\r\n",
        "  diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps1ZKu-WNuXO"
      },
      "source": [
        "### 오차역전파법을 사용한 학습 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MiYRmE4ObeJ"
      },
      "source": [
        "# 데이터 불러오기\r\n",
        "try:\r\n",
        "    import urllib.request\r\n",
        "except ImportError:\r\n",
        "    raise ImportError('You should use Python 3.x')\r\n",
        "import os.path\r\n",
        "import gzip\r\n",
        "import pickle\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import sys\r\n",
        "\r\n",
        "url_base = 'http://yann.lecun.com/exdb/mnist/'\r\n",
        "key_file = {\r\n",
        "    'train_img':'train-images-idx3-ubyte.gz',\r\n",
        "    'train_label':'train-labels-idx1-ubyte.gz',\r\n",
        "    'test_img':'t10k-images-idx3-ubyte.gz',\r\n",
        "    'test_label':'t10k-labels-idx1-ubyte.gz'\r\n",
        "}\r\n",
        "\r\n",
        "__file__ = os.pardir\r\n",
        "# print(__file__)\r\n",
        "dataset_dir = os.path.dirname(os.path.abspath(__file__))\r\n",
        "save_file = dataset_dir + \"/mnist.pkl\"\r\n",
        "\r\n",
        "train_num = 60000\r\n",
        "test_num = 10000\r\n",
        "img_dim = (1, 28, 28)\r\n",
        "img_size = 784\r\n",
        "\r\n",
        "\r\n",
        "def _download(file_name):\r\n",
        "    file_path = dataset_dir + \"/\" + file_name\r\n",
        "    \r\n",
        "    if os.path.exists(file_path):\r\n",
        "        return\r\n",
        "\r\n",
        "    print(\"Downloading \" + file_name + \" ... \")\r\n",
        "    urllib.request.urlretrieve(url_base + file_name, file_path)\r\n",
        "    print(\"Done\")\r\n",
        "    \r\n",
        "def download_mnist():\r\n",
        "    for v in key_file.values():\r\n",
        "       _download(v)\r\n",
        "        \r\n",
        "def _load_label(file_name):\r\n",
        "    file_path = dataset_dir + \"/\" + file_name\r\n",
        "    \r\n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\r\n",
        "    with gzip.open(file_path, 'rb') as f:\r\n",
        "            labels = np.frombuffer(f.read(), np.uint8, offset=8)\r\n",
        "    print(\"Done\")\r\n",
        "    \r\n",
        "    return labels\r\n",
        "\r\n",
        "def _load_img(file_name):\r\n",
        "    file_path = dataset_dir + \"/\" + file_name\r\n",
        "    \r\n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")    \r\n",
        "    with gzip.open(file_path, 'rb') as f:\r\n",
        "            data = np.frombuffer(f.read(), np.uint8, offset=16)\r\n",
        "    data = data.reshape(-1, img_size)\r\n",
        "    print(\"Done\")\r\n",
        "    \r\n",
        "    return data\r\n",
        "    \r\n",
        "def _convert_numpy():\r\n",
        "    dataset = {}\r\n",
        "    dataset['train_img'] =  _load_img(key_file['train_img'])\r\n",
        "    dataset['train_label'] = _load_label(key_file['train_label'])    \r\n",
        "    dataset['test_img'] = _load_img(key_file['test_img'])\r\n",
        "    dataset['test_label'] = _load_label(key_file['test_label'])\r\n",
        "    \r\n",
        "    return dataset\r\n",
        "\r\n",
        "def init_mnist():\r\n",
        "    download_mnist()\r\n",
        "    dataset = _convert_numpy()\r\n",
        "    print(\"Creating pickle file ...\")\r\n",
        "    with open(save_file, 'wb') as f:\r\n",
        "        pickle.dump(dataset, f, -1)\r\n",
        "    print(\"Done!\")\r\n",
        "\r\n",
        "def _change_one_hot_label(X):\r\n",
        "    T = np.zeros((X.size, 10))\r\n",
        "    for idx, row in enumerate(T):\r\n",
        "        row[X[idx]] = 1\r\n",
        "        \r\n",
        "    return T\r\n",
        "    \r\n",
        "\r\n",
        "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\r\n",
        "    \"\"\"MNIST 데이터셋 읽기\r\n",
        "    \r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    normalize : 이미지의 픽셀 값을 0.0~1.0 사이의 값으로 정규화할지 정한다.\r\n",
        "    one_hot_label : \r\n",
        "        one_hot_label이 True면、레이블을 원-핫(one-hot) 배열로 돌려준다.\r\n",
        "        one-hot 배열은 예를 들어 [0,0,1,0,0,0,0,0,0,0]처럼 한 원소만 1인 배열이다.\r\n",
        "    flatten : 입력 이미지를 1차원 배열로 만들지를 정한다. \r\n",
        "    \r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    (훈련 이미지, 훈련 레이블), (시험 이미지, 시험 레이블)\r\n",
        "    \"\"\"\r\n",
        "    if not os.path.exists(save_file):\r\n",
        "        init_mnist()\r\n",
        "        \r\n",
        "    with open(save_file, 'rb') as f:\r\n",
        "        dataset = pickle.load(f)\r\n",
        "    \r\n",
        "    if normalize:\r\n",
        "        for key in ('train_img', 'test_img'):\r\n",
        "            dataset[key] = dataset[key].astype(np.float32)\r\n",
        "            dataset[key] /= 255.0\r\n",
        "            \r\n",
        "    if one_hot_label:\r\n",
        "        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])\r\n",
        "        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])    \r\n",
        "    \r\n",
        "    if not flatten:\r\n",
        "         for key in ('train_img', 'test_img'):\r\n",
        "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\r\n",
        "\r\n",
        "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) \r\n",
        "\r\n",
        "\r\n",
        "# if __name__ == '__main__':\r\n",
        "#     init_mnist()\r\n",
        "\r\n",
        "# MNIST 데이터셋을 내려받아 그 이미지를 넘파이 배열로 변화해주는 파이썬 스크립트 사용\r\n",
        "# import sys, os\r\n",
        "# sys.path.append(os.pardir)\r\n",
        "# # from dataset.mnist import load_mnist\r\n",
        "# # load_mnist()\r\n",
        "\r\n",
        "# (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\r\n",
        "\r\n",
        "# print(x_train.shape)\r\n",
        "# print(t_train.shape)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqBgqgH5NxMG",
        "outputId": "65532ad1-b1aa-4bda-8eeb-32bb052789ae"
      },
      "source": [
        "from tqdm import tqdm\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\r\n",
        "\r\n",
        "# print(x_train.shape)\r\n",
        "# print(t_train.shape)\r\n",
        "\r\n",
        "train_loss_list = []\r\n",
        "train_acc_list = []\r\n",
        "test_acc_list = []\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# 하이퍼파라미터 : 사람이 조정하는 매개변수\r\n",
        "iters_num = 10000\r\n",
        "train_size = x_train.shape[0]\r\n",
        "batch_size = 100 # 미니배치 크기\r\n",
        "learning_rate = 0.1\r\n",
        "\r\n",
        "# 1에포크 당 반복 수 \r\n",
        "iter_per_epoch = max(train_size/batch_size, 1)\r\n",
        "\r\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\r\n",
        "\r\n",
        "for i in tqdm(range(iters_num)) :\r\n",
        "  # 미니배치 획득\r\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\r\n",
        "  x_batch = x_train[batch_mask]\r\n",
        "  t_batch = t_train[batch_mask]\r\n",
        "\r\n",
        "  # 기울기 계산\r\n",
        "  # grad = network.numerical_gradient(x_batch, t_batch)\r\n",
        "  grad = network.gradient(x_batch, t_batch ) # 성능 개선판(역전파)\r\n",
        "\r\n",
        "  # 매개변수 갱신\r\n",
        "  for key in ('W1', 'b1', 'W2', 'b2') :\r\n",
        "    network.params[key] -= learning_rate * grad[key]\r\n",
        "\r\n",
        "  # 학습 경과 기록\r\n",
        "  loss = network.loss(x_batch, t_batch)\r\n",
        "  train_loss_list.append(loss)\r\n",
        "\r\n",
        "  # 1에포크당 정확도 계산\r\n",
        "  if i % iter_per_epoch == 0 :\r\n",
        "    train_acc = network.accuracy(x_train, t_train)\r\n",
        "    test_acc = network.accuracy(x_test, t_test)\r\n",
        "    train_acc_list.append(train_acc)\r\n",
        "    test_acc_list.append(test_acc)\r\n",
        "    print('train acc, test acc | '+str(train_acc)+\",\"+str(test_acc))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 32/10000 [00:00<43:13,  3.84it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.15275,0.1617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  6%|▋         | 632/10000 [00:02<00:56, 166.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.9062833333333333,0.9092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 1255/10000 [00:05<00:51, 169.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.9252,0.9272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 1843/10000 [00:07<00:47, 173.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.9332666666666667,0.9326\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▍       | 2458/10000 [00:09<00:43, 172.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.9463,0.9453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|███       | 3043/10000 [00:12<00:41, 167.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.95155,0.9474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 3662/10000 [00:14<00:36, 173.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.9571833333333334,0.9515\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 4234/10000 [00:17<00:34, 168.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.96065,0.9566\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 4835/10000 [00:19<00:32, 160.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.964,0.9607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 5446/10000 [00:21<00:26, 170.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.9674333333333334,0.962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 6042/10000 [00:24<00:22, 172.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.96975,0.9636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 66%|██████▋   | 6635/10000 [00:26<00:19, 172.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.9713333333333334,0.9665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 7231/10000 [00:28<00:15, 175.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.9731833333333333,0.9679\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 7845/10000 [00:31<00:12, 169.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.9755166666666667,0.9672\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 8434/10000 [00:33<00:09, 170.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.9764333333333334,0.9692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 9057/10000 [00:36<00:05, 173.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.9772833333333333,0.9692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 96%|█████████▋| 9642/10000 [00:38<00:02, 169.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.9793333333333333,0.9713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:39<00:00, 252.23it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gImRqHGUWokY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}