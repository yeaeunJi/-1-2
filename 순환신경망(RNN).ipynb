{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "순환신경망(RNN).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNtJM+joevMX+wa4XYJPlnO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeaeunJi/deep_learning-/blob/main/%EC%88%9C%ED%99%98%EC%8B%A0%EA%B2%BD%EB%A7%9D(RNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIs9Y3LJFboB"
      },
      "source": [
        "# 순환 신경망(RNN)\r\n",
        "- 피드포워드(feed forward) \r\n",
        "  - 흐름의 반향이 반방향인 신경망으로 폭포수처럼 한 방향으로만 신호가 전달되는 신경망임\r\n",
        "  - 구성이 단순하여 구조를 이해하기 쉽고 많은 문제에 응용 가능하지만, 시계열 데이터를 잘 다루지 못함(시계열 데이터의 성질(패턴)을 충분히 학습하지 못함\r\n",
        "  - 이 문제를 해결할 수 있는 것이 순환 신경망(Reccurent Neural Network, RNN)임\r\n",
        "\r\n",
        "## 확률과 언어 모델\r\n",
        "### word2vec을 확률 관점에서 본다면\r\n",
        "- 맥락 단어드로부터 타깃 단어를 추측하는 일을 수행하는 것이 word2vec, 그중에서도 CBOW 모델임\r\n",
        "- CBOW 모델을 확률로 나타낸다면 사후 확률로 나타낼 수 있는데, 맥락 단어가 주어졌을 떄, 타깃 단어가 일어날 확률을 의미\r\n",
        "- 만약 맥락을 왼쪽 윈도우만으로 설정하여 생각해본다면, 타깃 단어 기준으로 왼쪽의 윈도우 사이즈 크기만큼의 단어가 주어졌을 때, 타킷 단어가 일어날 확률로 생각해볼 수 있음\r\n",
        "- 이 COBOW 모델이 다루는 손실함수 교차 엔트로피 오차를 유도하게 된다면 \r\n",
        "\r\n",
        "      L = -logP(Wt| Wt-2, Wt-1)\r\n",
        "\r\n",
        "  - 말뭉치 전체의 손실 함수의 총합을 최소화하는 가중치 매개변수를 찾는 것을 통해서 맥락으로부터 타깃을 더 정확하게 추측하게 됨\r\n",
        "  - 이렇게 학습을 진행한다면, 단어의 의미가 인코딩된 '단어의 분산표현' 역시 얻을 수 있음\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG-Z4GkiHoQQ"
      },
      "source": [
        "### 언어 모델(Language Model)\r\n",
        "- 단어 나열에 확률을 부여한 것으로, 특정 단어의 순서가 얼마나 자연스러운지, 일어날 가능성이 어느 정도인지를 확률로 평가함\r\n",
        "  - 예)  i run이 i good보다 높은 확률을 출력\r\n",
        "- 활용 사례\r\n",
        "  - 기계번역과 음성 인식 등에 사용 가능\r\n",
        "  - 새로운 문장 생성 시 사용 가능(언어 모델은 단어 수선의 자연스로움을 확률적으로 평가 가능하므로, 그 확률분퍼에 따라 다음에 적합한 단어를 추출할 수 있기 때문)\r\n",
        "- 언어 모델을 수식으로 설명해보면 그 순서로 출현할 확률(동시에 발생할 확률)인 동시 확률을 사후 확률을 사용하여 분해 가능\r\n",
        "  - 동시 확률은 사후 확률의 총곱으로 나타낼 수 있음\r\n",
        "  - 이 사후 확률은 타깃 단어보다 왼쪽에 위치한 모든 단어를 맥락으로 했을 때의 확률임(조건부 언어모델)\r\n",
        "\r\n",
        "** 참고 **\r\n",
        "\r\n",
        "마르코프 연쇄(Markov Chain) 또는 마르코프 모델(Markov Model)\r\n",
        "  - 미래의 상태가 현재 상태에만 의존해 결정되는 것을 의미\r\n",
        "\r\n",
        "- CBOW 모델에도 이러한 언어 모델을 적용해볼 수 있지만 이 모델의 특성 상 맥락 안의 단어 순서가 무시된다는 한계가 존재함. 순서대신 분포를 사용\r\n",
        "  - 입력층에서 은닉층으로 맥락 단어 벡터를 계산 시 CBOW에서는 순서가 중요하지 않으므로 이 벡터들이 더해지게 되고 (you, say)와 (say, you)가 같은 맥락으로 취급\r\n",
        "\r\n",
        "- 이러한 문제를 해결하기 위해서 등장한 것이 순환 신경망임\r\n",
        "  - RNN은 맥락이 아무리 길어도 그 맥락의 정보를 기억하는 체계를 가지고 있으며, 긴 시계열 데이터라도 대응할수 있게됨  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r914t8q6KXCx"
      },
      "source": [
        "## RNN이란?\r\n",
        "- 순환이란 의미는 어떠한 장소에서 출발한 후 다시 되돌아오고, 이 과정이 반복되는 것을 의미\r\n",
        "- 이러한 순환이 일어나기 위해서는 닫힌 경로 혹은 순환하는 경로가 필요\r\n",
        "  - 이 경로를 데이터가 순환하면서 정보가 끊임없이 갱신됨\r\n",
        "  - 또한 데이터가 순환되기 때문에 과거의 정보를 기억하면서 동시에 최신 데이터로 갱신 가능\r\n",
        "\r\n",
        "- 각 시각t(t번째단어)의 RNN 계층은 그 계층에서 받는 입력과 1개 전의 RNN 계층으로부터의 복제된 출력을 받아 이 두 정보를 바당으로 현 시각의 출력을 계산함\r\n",
        "  - 이때 사용하는 활성화 함수는 tanh(쌍곡탄젠트, hyperbolic tangent 함수)를 이용해 출력을 변환함\r\n",
        "  - 현재의 출력은 한 시각 이전 출력에 기초해 계산되므로, h라는 상태를 가지고 있으며 이를 갱신한다고 해석 가능\r\n",
        "\r\n",
        "### BPTT(Backpropagation Through Time)\r\n",
        "- 시간 방향으로 펼친 신겸앙의 오차역전파법\r\n",
        "- 긴 시계열 데이터를 학습 시에는 오차역전파를 위해  매 시각 RNN 계층의 중간 데이터를 메모리에 유지해둬야하고, 시간 크기가 커지면 역전파의 기울기가 불안정해질 수 있음\r\n",
        "  - 신경망을 통과할 때마다 기울기 값이 조금씩 작아져 이전 시각 t까지 역전파되기 전에 0이 되어 소멸할 수 도 있음\r\n",
        "\r\n",
        "### Truncated BPTT \r\n",
        "- 따라서 큰 시계열 데이터를 취급 시에는 신경망 연결을 적당한 지점에서 잘라내어 작은 신경망을 여러개로 만들고 여기에서 오차역전파법을 수행함\r\n",
        "- 순전파의 연결을 그대로 유지하고 전파되지만 역전파의 연결을 잘라낸 블록단위로 학습을 수행)\r\n",
        "- 데이터를 순서대로 입력하는 것이 매우 중요\r\n",
        "\r\n",
        "### Truncated BPTT의 미니배치 학습\r\n",
        "- 데이터를 제공하는 시작 위치를 옮겨서 제공"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilsyudn0OmkZ"
      },
      "source": [
        "### RNN 계층 구현\r\n",
        "- RNN 처리를 한 단계만 수행하는 클래스\r\n",
        "- 데이터를 미니배치로 모아서 처리할 예정\r\n",
        "- 입력과 출력은 각 샘플 데이터를 행 방향으로 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExO9slhOFYKz"
      },
      "source": [
        "class RNN :\r\n",
        "  def __init__(self, Wx, Wh, b) :\r\n",
        "    self.params = [Wx, Wh, b]\r\n",
        "    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\r\n",
        "    self.cache = None\r\n",
        "\r\n",
        "  def forward(self, x, h_prev) :\r\n",
        "    Wx, Wh, b = self.params\r\n",
        "    t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b\r\n",
        "    h_next = np.tanh(t)\r\n",
        "\r\n",
        "    self.cache = (x, h_prev, h_next)\r\n",
        "    return h_next\r\n",
        "\r\n",
        "  def backward(self, dh_next) :\r\n",
        "    Wx, Wh, b = self.params\r\n",
        "    x, h_prev, h_next = self.cache\r\n",
        "\r\n",
        "    dt = dh_next * (1-h_next **2) # tanh의 역전파 값\r\n",
        "    db = np.sum(dt, axis=0)\r\n",
        "    dWh = np.matmul(h_prev.T, dt)\r\n",
        "    dh_prev = np.matmul(dt, Wh.T)\r\n",
        "    dWx = np.matmul(x.T, dt)\r\n",
        "    dx = np.matmul(dt, Wx.T)\r\n",
        "\r\n",
        "    self.grads[0][...] =  dWx\r\n",
        "    self.grads[1][...] = dWh\r\n",
        "    self.grads[2][...] = db\r\n",
        "\r\n",
        "    return dx, dh_prev\r\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6GBSxki1Fvr"
      },
      "source": [
        "### T개의 RNN 계층으로 구성된 Time RNN 계층 구현\r\n",
        "# 이전 계층의 은닉 상태를 인계받을지에 대한 플래그를 저장하는 stateful 인수\r\n",
        "import numpy as np\r\n",
        "class TimeRNN :\r\n",
        "  def __init__(self, Wx, Wh, b, stateful=False) :\r\n",
        "    self.params = [Wx, Wh, b] # Wx : 현재 시각에 대한 출력 가중치, Wh : 이전 출력에 대한 가중치, b: 편향에 대한 가중치\r\n",
        "    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)] \r\n",
        "    self.layers = None # 다수의 RNN 계층을 리스트로 저장하는 용도\r\n",
        "\r\n",
        "    self.h, self.dh = None, None # h : 순전파 시 마지막 RNN 계층의 은닉 상태(출력) 저장, dh : 역전파 시 하나 앞 블록의 은닉 상태(출력) 기울기 저장\r\n",
        "    self.stateful = stateful\r\n",
        "\r\n",
        "  def set_state(self, h) :\r\n",
        "    self.h = h\r\n",
        "  \r\n",
        "  def reset_state(self) :\r\n",
        "    self.h = None\r\n",
        "\r\n",
        "  def forward(self, xs) :\r\n",
        "    Wx, Wh, b = self.params # h 를 구하기 위해 필요한 값\r\n",
        "\r\n",
        "    # xs : T개 분량의 시계열 데이터를 하나로 모은 것\r\n",
        "    # N : 미니배치의 크기\r\n",
        "    # D : 입력 벡터의 차원 수\r\n",
        "    N, T, D = xs.shape # 입력데이터의 형상을 통해 필요한 행렬의 모양을 설정\r\n",
        "    D, H = Wx.shape # 데이터 x에 대한 가중치 형상\r\n",
        "\r\n",
        "    self.layers = []\r\n",
        "    hs = np.empty((N, T, H), dtype='f') # xs에 대한 출력값 \r\n",
        "\r\n",
        "    if not self.stateful or self.h is None :\r\n",
        "      self.h = np.zeros((N,H), dtype='f')\r\n",
        "\r\n",
        "    for t in range(T) : # 총 T회 반복되는 for\r\n",
        "      layer = RNN(*self.params) # *의 의미 : 리스트 원소들을 추출하여 메서드의 인수로 전달\r\n",
        "      self.h = layer.forward(xs[:, t, :], self.h) # 각 시각 t의 은닉 상태 계ㅆ산\r\n",
        "      hs[:, t, :] = self.h # 해당 인덱스(시각)의 값으로 설정\r\n",
        "      self.layers.append(layer)\r\n",
        "    pass # for\r\n",
        "\r\n",
        "    return hs\r\n",
        "\r\n",
        "  def backward(self, dhs) :\r\n",
        "    # dhs : 상류(출력쪽 층)에서부터 전해지는 기울기\r\n",
        "    # dhx : 하류로 보내는 기울기\r\n",
        "    # dh : 이전 시각의 은닉 상태 기울기 ---> seq2seq에 필요\r\n",
        "    Wx, Wh, b = self.params\r\n",
        "    N, T, H = dhs.shape\r\n",
        "    D, H = Wx.shape\r\n",
        "\r\n",
        "    dxs = np.empty((N,T,D), dtype='f') # 하류로 보낼 기울기를 담을 그릇인 dxs\r\n",
        "    dh = 0 \r\n",
        "    grads = [0,0,0]\r\n",
        "\r\n",
        "    for t in reversed(range(T)) :\r\n",
        "      layer = self.layers[t]\r\n",
        "      dx, dh = layer.backward(dhs[:, t, :] + dh) # 각 시각의 기울기 합산된 기울기(순전파 시 분기되었을 경우, 역전파는 각 기울기가 합산되어 전해짐)\r\n",
        "      dxs[:,t,:] = dx # 구한 각 시각의 기울기를 dxs의 해당 인덱스(시각)에 저장\r\n",
        "\r\n",
        "      for i,  grad in enumerate(layer.grads) :# 가중치 매개변수에 대한 각 RNN 계층의 가중치 기울기를 합산\r\n",
        "        grads[i] += grad\r\n",
        "\r\n",
        "    ## Time RNN 계층 안에는 여러 RNN 계층이 존재하는데, 그 계층들은 똑같은 가중치를 사용하고 있음\r\n",
        "    # 따라서 Time RNN 계층의 최종 가중치의 기울기는 각 RNN 계층의 가중치 기울기를 모두 더한 것이 됨\r\n",
        "\r\n",
        "    for i, grad in enumerate(layer.grads) :\r\n",
        "      self.grads[i][...] = grad # 합산 한 가중치 기울기를 합산한 결과를 멤버 변수 self.grads에 덮어씀\r\n",
        "    self.dh = dh\r\n",
        "\r\n",
        "    return dxs "
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ATj3p5HufO2"
      },
      "source": [
        "## 시계열 데이터 처리 계층 구현\r\n",
        "- 시계열 데이터를 처리하는 계층 및 RNN을 사용하여 언어모델을 구현\r\n",
        "  - RNN을 사용한 언어 모델 ===> RNN Language Model(RNNLM)\r\n",
        "\r\n",
        "### RNNLM의 전체 그림\r\n",
        "- 첫번째 층 \r\n",
        "  - 단어 ID를 단어의 분산 표현(단어 벡터)로 변환하는 Embedding 계층\r\n",
        "  - 변환된 분산 표현은 다음 RNN 계층으로 입력됨\r\n",
        "\r\n",
        "- 두번째 층\r\n",
        "  - 은닉 상태(출력)을 다음 층으로 출력하면서 동시에 다음 시각의 RNN 계층으로 출력\r\n",
        "\r\n",
        "- 세번째 층\r\n",
        "  - Affine 계층으로 모든 가중치와 곱하여 은닉 상태 출력\r\n",
        "\r\n",
        "- 네번째 층\r\n",
        "  - Softmax 계층으로 점수를 확률로 변환\r\n",
        "\r\n",
        "- RNNLM은 지금까지 입력된 단어를 기억하고, 그것을 바탕으로 다음에 출현할 단어를 예측할 수 있음. (지금까지 단어 시퀀스의 과거의 정보를 응집된 은닉 상태 벡터로 저장하여 맥락을 기억)\r\n",
        "  - RNN 계층으로 이러한 일이 가능해지는데 이 계층은 과거에서 현재로 데이터를 계속 흘려보내줌으로써 과거의 정보를 인코딩해 저장\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSQldPaLwdH1"
      },
      "source": [
        "## Time 계층 구현\r\n",
        "- 시계열 데이터를 한꺼번에 처리하는 Time Embedding, Time Affine 계층 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwp74WpI0Btv"
      },
      "source": [
        "# https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/common/time_layers.py\r\n",
        "def softmax(x):\r\n",
        "    if x.ndim == 2:\r\n",
        "        x = x - x.max(axis=1, keepdims=True)\r\n",
        "        x = np.exp(x)\r\n",
        "        x /= x.sum(axis=1, keepdims=True)\r\n",
        "    elif x.ndim == 1:\r\n",
        "        x = x - np.max(x)\r\n",
        "        x = np.exp(x) / np.sum(np.exp(x))\r\n",
        "\r\n",
        "    return x\r\n",
        "\r\n",
        "class Embedding:\r\n",
        "    def __init__(self, W):\r\n",
        "        self.params = [W]\r\n",
        "        self.grads = [np.zeros_like(W)]\r\n",
        "        self.idx = None\r\n",
        "\r\n",
        "    def forward(self, idx):\r\n",
        "        W, = self.params\r\n",
        "        self.idx = idx\r\n",
        "        # print(W.shape)\r\n",
        "        # print(idx)\r\n",
        "        out = W[idx]\r\n",
        "        return out\r\n",
        "\r\n",
        "    def backward(self, dout):\r\n",
        "        dW, = self.grads\r\n",
        "        dW[...] = 0\r\n",
        "        np.add.at(dW, self.idx, dout)\r\n",
        "        return None\r\n",
        "\r\n",
        "class TimeEmbedding:\r\n",
        "    def __init__(self, W):\r\n",
        "        self.params = [W]\r\n",
        "        self.grads = [np.zeros_like(W)]\r\n",
        "        self.layers = None\r\n",
        "        self.W = W\r\n",
        "\r\n",
        "    def forward(self, xs):\r\n",
        "        N, T = xs.shape\r\n",
        "        V, D = self.W.shape\r\n",
        "\r\n",
        "        out = np.empty((N, T, D), dtype='f')\r\n",
        "        self.layers = []\r\n",
        "\r\n",
        "        for t in range(T):\r\n",
        "            layer = Embedding(self.W)\r\n",
        "            # print(xs[:, t])\r\n",
        "            out[:, t, :] = layer.forward(xs[:, t])\r\n",
        "\r\n",
        "            self.layers.append(layer)\r\n",
        "\r\n",
        "        return out\r\n",
        "\r\n",
        "    def backward(self, dout):\r\n",
        "        N, T, D = dout.shape\r\n",
        "\r\n",
        "        grad = 0\r\n",
        "        for t in range(T):\r\n",
        "            layer = self.layers[t]\r\n",
        "            layer.backward(dout[:, t, :])\r\n",
        "            grad += layer.grads[0]\r\n",
        "\r\n",
        "        self.grads[0][...] = grad\r\n",
        "        return None\r\n",
        "\r\n",
        "\r\n",
        "class TimeAffine:\r\n",
        "    def __init__(self, W, b):\r\n",
        "        self.params = [W, b]\r\n",
        "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\r\n",
        "        self.x = None\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        N, T, D = x.shape\r\n",
        "        W, b = self.params\r\n",
        "\r\n",
        "        rx = x.reshape(N*T, -1)\r\n",
        "        out = np.dot(rx, W) + b\r\n",
        "        self.x = x\r\n",
        "        return out.reshape(N, T, -1)\r\n",
        "\r\n",
        "    def backward(self, dout):\r\n",
        "        x = self.x\r\n",
        "        N, T, D = x.shape\r\n",
        "        W, b = self.params\r\n",
        "\r\n",
        "        dout = dout.reshape(N*T, -1)\r\n",
        "        rx = x.reshape(N*T, -1)\r\n",
        "\r\n",
        "        db = np.sum(dout, axis=0)\r\n",
        "        dW = np.dot(rx.T, dout)\r\n",
        "        dx = np.dot(dout, W.T)\r\n",
        "        dx = dx.reshape(*x.shape)\r\n",
        "\r\n",
        "        self.grads[0][...] = dW\r\n",
        "        self.grads[1][...] = db\r\n",
        "\r\n",
        "        return dx\r\n",
        "\r\n",
        "class TimeSoftmaxWithLoss:\r\n",
        "    def __init__(self):\r\n",
        "        self.params, self.grads = [], []\r\n",
        "        self.cache = None\r\n",
        "        self.ignore_label = -1\r\n",
        "\r\n",
        "    def forward(self, xs, ts):\r\n",
        "        N, T, V = xs.shape\r\n",
        "\r\n",
        "        if ts.ndim == 3:  # 정답 레이블이 원핫 벡터인 경우\r\n",
        "            ts = ts.argmax(axis=2)\r\n",
        "\r\n",
        "        mask = (ts != self.ignore_label)\r\n",
        "\r\n",
        "        # 배치용과 시계열용을 정리(reshape)\r\n",
        "        xs = xs.reshape(N * T, V)\r\n",
        "        ts = ts.reshape(N * T)\r\n",
        "        mask = mask.reshape(N * T)\r\n",
        "\r\n",
        "        ys = softmax(xs)\r\n",
        "        ls = np.log(ys[np.arange(N * T), ts])\r\n",
        "        ls *= mask  # ignore_label에 해당하는 데이터는 손실을 0으로 설정\r\n",
        "        loss = -np.sum(ls)\r\n",
        "        loss /= mask.sum()\r\n",
        "\r\n",
        "        self.cache = (ts, ys, mask, (N, T, V))\r\n",
        "        return loss\r\n",
        "\r\n",
        "    def backward(self, dout=1):\r\n",
        "        ts, ys, mask, (N, T, V) = self.cache\r\n",
        "\r\n",
        "        dx = ys\r\n",
        "        dx[np.arange(N * T), ts] -= 1\r\n",
        "        dx *= dout\r\n",
        "        dx /= mask.sum()\r\n",
        "        dx *= mask[:, np.newaxis]  # ignore_labelㅇㅔ 해당하는 데이터는 기울기를 0으로 설정\r\n",
        "\r\n",
        "        dx = dx.reshape((N, T, V))\r\n",
        "\r\n",
        "        return dx"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_li3NlCHvaoO"
      },
      "source": [
        "# 위에서 그린 전체 그림의 신경망에서 순전파로 한정하여 출력 결과를 관찰\r\n",
        "# 입력 데이터 : You say goodbye and I say hello.\r\n",
        "import numpy as np\r\n",
        "class SimpleRnnlm :\r\n",
        "  def __init__(self, vocab_size, wordvec_size, hidden_size) :\r\n",
        "    V, D, H = vocab_size, wordvec_size, hidden_size\r\n",
        "    rn  = np.random.randn\r\n",
        "\r\n",
        "    # 가중치 초기화 \r\n",
        "    # RNN 계층과 Affine 계층에서 Xavier 초깃값(사비에르초깃값) 이용\r\n",
        "    # 사비에르 초깃값 : 이전 계층의 노드가 n개라면 표준편차가 1/ root(n) 인 분포들로 값들을 초기화\r\n",
        "    embed_W = (rn(V,D) / 100).astype('f')\r\n",
        "    rnn_Wx = (rn(D,H) / np.sqrt(D)).astype('f')\r\n",
        "    rnn_Wh = (rn(H,H) / np.sqrt(H)).astype('f')\r\n",
        "    rnn_b = np.zeros(H).astype('f')\r\n",
        "    affine_W = (rn(H,V) / np.sqrt(H)).astype('f')\r\n",
        "    affine_b = np.zeros(V).astype('f')\r\n",
        "\r\n",
        "    # 계층 생성\r\n",
        "    self.layers = [\r\n",
        "        TimeEmbedding(embed_W),\r\n",
        "        TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True), # Truncated BPTT로 학습으로 이전 시각의 은닉 상태를 계승 가능하도록 설정\r\n",
        "        TimeAffine(affine_W, affine_b)\r\n",
        "    ]\r\n",
        "\r\n",
        "    self.loss_layer = TimeSoftmaxWithLoss()\r\n",
        "    self.rnn_layer = self.layers[1]\r\n",
        "\r\n",
        "    # 모든 가중치와 기울기를 리스트에 모음\r\n",
        "    self.params, self.grads = [], []\r\n",
        "    for layer in self.layers:\r\n",
        "      self.params += layer.params\r\n",
        "      self.grads += layer.grads\r\n",
        "\r\n",
        "  def forward(self, xs, ts) :\r\n",
        "    for layer in self.layers :\r\n",
        "      xs = layer.forward(xs)\r\n",
        "    loss = self.loss_layer.forward(xs, ts)\r\n",
        "    return loss\r\n",
        "\r\n",
        "  def backward(self, dout=1) :\r\n",
        "    dout = self.loss_layer.backward(dout)\r\n",
        "    for layer in reversed(self.layers) :\r\n",
        "      dout = layer.backward(dout)\r\n",
        "    return dout\r\n",
        "\r\n",
        "  def reset_state(self) :\r\n",
        "    self.rnn_layer.reset_state() # 신경망의 상태를 초기화함"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9lCv8PX03bs"
      },
      "source": [
        "### 언어 모델의 평가\r\n",
        "- 언어 모델은 주어진 과거의 단어로부터 다음에 출현할 단어의 확률 분포를 출력함\r\n",
        "  - 이때, 언어 모델의 예측 성능을 평가하는 척도로 혼란도(퍼플렉서티, perplexity)를 자주 이요d\r\n",
        "\r\n",
        "- 퍼플렉서티 \r\n",
        " - 퍼플렉서티는 작을수록 좋은 것인데, 간단하게 말하면 확률의 역수라는 개념과 비슷(입력 데이터가 하나일 때)\r\n",
        "- 퍼플렉서티의 값 해석 방법\r\n",
        "  - 분기수(number of branches)로 해석 가능\r\n",
        "  - 다음에 취할 수 있는 선택사항의 수로, 좋은 모델이 예측한 분기수가 1.25라는 것은 다음에 출현할 수 있는 단어의 후보가 1개 정도라는 의미\r\n",
        "  - 입력 데이터가 여러 개일 때문 Loss를 사용해 e의 L승한 값이 퍼플렉서티가 됨\r\n",
        "  (여러 데이터를 입력데이터로 받은 softmax로 도출된 확률분포에서의 교차 엔트로피 오차)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5KiE6EU2LFT"
      },
      "source": [
        "### RNNLM 학습 코드\r\n",
        "- PTB데이터 셋을 이용하여 RNNLM 학습을 수행하되 처음 1000개 단어만 사용하고, 전체 데이터 셋을 대상으로 학습하는 것은 다음에 구현할 예정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebimgQMS2KA9"
      },
      "source": [
        "# https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/common/optimizer.py\r\n",
        "class SGD:\r\n",
        "    '''\r\n",
        "    확률적 경사하강법(Stochastic Gradient Descent)\r\n",
        "    '''\r\n",
        "    def __init__(self, lr=0.01):\r\n",
        "        self.lr = lr\r\n",
        "        \r\n",
        "    def update(self, params, grads):\r\n",
        "        for i in range(len(params)):\r\n",
        "            params[i] -= self.lr * grads[i]"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TstPWruz2pLs"
      },
      "source": [
        "# coding: utf-8\r\n",
        "import sys\r\n",
        "import os\r\n",
        "sys.path.append('..')\r\n",
        "try:\r\n",
        "    import urllib.request\r\n",
        "except ImportError:\r\n",
        "    raise ImportError('Use Python3!')\r\n",
        "import pickle\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "url_base = 'https://raw.githubusercontent.com/tomsercu/lstm/master/data/'\r\n",
        "key_file = {\r\n",
        "    'train':'ptb.train.txt',\r\n",
        "    'test':'ptb.test.txt',\r\n",
        "    'valid':'ptb.valid.txt'\r\n",
        "}\r\n",
        "save_file = {\r\n",
        "    'train':'ptb.train.npy',\r\n",
        "    'test':'ptb.test.npy',\r\n",
        "    'valid':'ptb.valid.npy'\r\n",
        "}\r\n",
        "vocab_file = 'ptb.vocab.pkl'\r\n",
        "__file__ = os.pardir\r\n",
        "dataset_dir = os.path.dirname(os.path.abspath(__file__))\r\n",
        "\r\n",
        "\r\n",
        "def _download(file_name):\r\n",
        "    file_path = dataset_dir + '/' + file_name\r\n",
        "    if os.path.exists(file_path):\r\n",
        "        return\r\n",
        "\r\n",
        "    print('Downloading ' + file_name + ' ... ')\r\n",
        "\r\n",
        "    try:\r\n",
        "        urllib.request.urlretrieve(url_base + file_name, file_path)\r\n",
        "    except urllib.error.URLError:\r\n",
        "        import ssl\r\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\r\n",
        "        urllib.request.urlretrieve(url_base + file_name, file_path)\r\n",
        "\r\n",
        "    print('Done')\r\n",
        "\r\n",
        "\r\n",
        "def load_vocab():\r\n",
        "    vocab_path = dataset_dir + '/' + vocab_file\r\n",
        "\r\n",
        "    if os.path.exists(vocab_path):\r\n",
        "        with open(vocab_path, 'rb') as f:\r\n",
        "            word_to_id, id_to_word = pickle.load(f)\r\n",
        "        return word_to_id, id_to_word\r\n",
        "\r\n",
        "    word_to_id = {}\r\n",
        "    id_to_word = {}\r\n",
        "    data_type = 'train'\r\n",
        "    file_name = key_file[data_type]\r\n",
        "    file_path = dataset_dir + '/' + file_name\r\n",
        "\r\n",
        "    _download(file_name)\r\n",
        "\r\n",
        "    words = open(file_path).read().replace('\\n', '<eos>').strip().split()\r\n",
        "\r\n",
        "    for i, word in enumerate(words):\r\n",
        "        if word not in word_to_id:\r\n",
        "            tmp_id = len(word_to_id)\r\n",
        "            word_to_id[word] = tmp_id\r\n",
        "            id_to_word[tmp_id] = word\r\n",
        "\r\n",
        "    with open(vocab_path, 'wb') as f:\r\n",
        "        pickle.dump((word_to_id, id_to_word), f)\r\n",
        "\r\n",
        "    return word_to_id, id_to_word\r\n",
        "\r\n",
        "\r\n",
        "def load_data(data_type='train'):\r\n",
        "    '''\r\n",
        "        :param data_type: 데이터 유형: 'train' or 'test' or 'valid (val)'\r\n",
        "        :return:\r\n",
        "    '''\r\n",
        "    if data_type == 'val': data_type = 'valid'\r\n",
        "    save_path = dataset_dir + '/' + save_file[data_type]\r\n",
        "\r\n",
        "    word_to_id, id_to_word = load_vocab()\r\n",
        "\r\n",
        "    if os.path.exists(save_path):\r\n",
        "        corpus = np.load(save_path)\r\n",
        "        return corpus, word_to_id, id_to_word\r\n",
        "\r\n",
        "    file_name = key_file[data_type]\r\n",
        "    file_path = dataset_dir + '/' + file_name\r\n",
        "    _download(file_name)\r\n",
        "\r\n",
        "    words = open(file_path).read().replace('\\n', '<eos>').strip().split()\r\n",
        "    corpus = np.array([word_to_id[w] for w in words])\r\n",
        "\r\n",
        "    np.save(save_path, corpus)\r\n",
        "    return corpus, word_to_id, id_to_word\r\n",
        "\r\n"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BYnqPwP2sLM",
        "outputId": "4caf5ff3-d191-47b7-c231-d2eb1a8c2296"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# 하이퍼파라미터 설정\r\n",
        "batch_size = 10\r\n",
        "wordvec_size = 100\r\n",
        "hidden_size = 100 # RNN의 은닉 상태 벡터의 원소 수\r\n",
        "time_size = 5 # Truncated BPTT가 한 번에 펼치는 시간 크기\r\n",
        "lr = 0.1\r\n",
        "max_epoch = 100\r\n",
        "\r\n",
        "# 학습 데이터 읽기(전체 중 1000개만)\r\n",
        "corpus, word_to_id, id_to_word = load_data('train')\r\n",
        "corpus_size = 1000\r\n",
        "corpus = corpus[:corpus_size]\r\n",
        "vocab_size = int(max(corpus) +1)\r\n",
        "\r\n",
        "xs = corpus[:-1] # 입력\r\n",
        "ts = corpus[1:] # 출력(정답 레이블)\r\n",
        "data_size = len(xs)\r\n",
        "print('말뭉치 크기 : %d, 어휘 수 : %d' % (corpus_size, vocab_size))\r\n",
        "\r\n",
        "# 학습 시 사용하는 변수\r\n",
        "max_iters = data_size // (batch_size * time_size)\r\n",
        "time_idx = 0\r\n",
        "total_loss = 0\r\n",
        "loss_count = 0\r\n",
        "ppl_list = []\r\n",
        "\r\n",
        "# 모델 생성 \r\n",
        "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\r\n",
        "optimizer = SGD(lr)\r\n",
        "\r\n",
        "# 각 미니배치에서 샘플을 읽기 시작 위치를 계산\r\n",
        "jump = (corpus_size - 1) // batch_size\r\n",
        "offsets = [ i * jump for i in range(batch_size)]\r\n",
        "# print(offsets)\r\n",
        "for epoch in range(max_epoch) :\r\n",
        "  for iter in range(max_iters) :\r\n",
        "    # 미니배치 획득\r\n",
        "    batch_x = np.empty((batch_size, time_size), dtype='i')\r\n",
        "    batch_t = np.empty((batch_size, time_size), dtype='i')\r\n",
        "\r\n",
        "    for t in range(time_size) :\r\n",
        "      for i, offset in enumerate(offsets) :\r\n",
        "        batch_x[i, t] = xs[(offset + time_idx) % data_size]\r\n",
        "        batch_t[i, t] = ts[(offset + time_idx) % data_size]\r\n",
        "      time_dix += 1\r\n",
        "    # print(batch_x)\r\n",
        "    # 기울기를 구하여 매개변수 갱신\r\n",
        "    loss = model.forward(batch_x, batch_t)\r\n",
        "    model.backward()\r\n",
        "    optimizer.update(model.params, model.grads)\r\n",
        "    total_loss += loss\r\n",
        "    loss_count += 1\r\n",
        "    \r\n",
        "  # 엑폭마다 퍼플렉서티 평가\r\n",
        "  ppl = np.exp(total_loss / loss_count)\r\n",
        "  print('| 에폭 %d | 퍼플렉서티 %.2f' % (epoch+1, ppl))\r\n",
        "\r\n",
        "ppl_list.append(float(ppl))\r\n",
        "total_loss, loss_count = 0,0"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "말뭉치 크기 : 1000, 어휘 수 : 418\n",
            "| 에폭 1 | 퍼플렉서티 138.23\n",
            "| 에폭 2 | 퍼플렉서티 35.11\n",
            "| 에폭 3 | 퍼플렉서티 16.42\n",
            "| 에폭 4 | 퍼플렉서티 9.80\n",
            "| 에폭 5 | 퍼플렉서티 6.87\n",
            "| 에폭 6 | 퍼플렉서티 5.34\n",
            "| 에폭 7 | 퍼플렉서티 4.42\n",
            "| 에폭 8 | 퍼플렉서티 3.83\n",
            "| 에폭 9 | 퍼플렉서티 3.42\n",
            "| 에폭 10 | 퍼플렉서티 3.12\n",
            "| 에폭 11 | 퍼플렉서티 2.89\n",
            "| 에폭 12 | 퍼플렉서티 2.72\n",
            "| 에폭 13 | 퍼플렉서티 2.57\n",
            "| 에폭 14 | 퍼플렉서티 2.46\n",
            "| 에폭 15 | 퍼플렉서티 2.36\n",
            "| 에폭 16 | 퍼플렉서티 2.28\n",
            "| 에폭 17 | 퍼플렉서티 2.21\n",
            "| 에폭 18 | 퍼플렉서티 2.15\n",
            "| 에폭 19 | 퍼플렉서티 2.09\n",
            "| 에폭 20 | 퍼플렉서티 2.05\n",
            "| 에폭 21 | 퍼플렉서티 2.01\n",
            "| 에폭 22 | 퍼플렉서티 1.97\n",
            "| 에폭 23 | 퍼플렉서티 1.94\n",
            "| 에폭 24 | 퍼플렉서티 1.91\n",
            "| 에폭 25 | 퍼플렉서티 1.88\n",
            "| 에폭 26 | 퍼플렉서티 1.85\n",
            "| 에폭 27 | 퍼플렉서티 1.83\n",
            "| 에폭 28 | 퍼플렉서티 1.81\n",
            "| 에폭 29 | 퍼플렉서티 1.79\n",
            "| 에폭 30 | 퍼플렉서티 1.77\n",
            "| 에폭 31 | 퍼플렉서티 1.76\n",
            "| 에폭 32 | 퍼플렉서티 1.74\n",
            "| 에폭 33 | 퍼플렉서티 1.73\n",
            "| 에폭 34 | 퍼플렉서티 1.71\n",
            "| 에폭 35 | 퍼플렉서티 1.70\n",
            "| 에폭 36 | 퍼플렉서티 1.69\n",
            "| 에폭 37 | 퍼플렉서티 1.68\n",
            "| 에폭 38 | 퍼플렉서티 1.67\n",
            "| 에폭 39 | 퍼플렉서티 1.66\n",
            "| 에폭 40 | 퍼플렉서티 1.65\n",
            "| 에폭 41 | 퍼플렉서티 1.64\n",
            "| 에폭 42 | 퍼플렉서티 1.63\n",
            "| 에폭 43 | 퍼플렉서티 1.62\n",
            "| 에폭 44 | 퍼플렉서티 1.62\n",
            "| 에폭 45 | 퍼플렉서티 1.61\n",
            "| 에폭 46 | 퍼플렉서티 1.60\n",
            "| 에폭 47 | 퍼플렉서티 1.60\n",
            "| 에폭 48 | 퍼플렉서티 1.59\n",
            "| 에폭 49 | 퍼플렉서티 1.58\n",
            "| 에폭 50 | 퍼플렉서티 1.58\n",
            "| 에폭 51 | 퍼플렉서티 1.57\n",
            "| 에폭 52 | 퍼플렉서티 1.57\n",
            "| 에폭 53 | 퍼플렉서티 1.56\n",
            "| 에폭 54 | 퍼플렉서티 1.56\n",
            "| 에폭 55 | 퍼플렉서티 1.55\n",
            "| 에폭 56 | 퍼플렉서티 1.55\n",
            "| 에폭 57 | 퍼플렉서티 1.54\n",
            "| 에폭 58 | 퍼플렉서티 1.54\n",
            "| 에폭 59 | 퍼플렉서티 1.54\n",
            "| 에폭 60 | 퍼플렉서티 1.53\n",
            "| 에폭 61 | 퍼플렉서티 1.53\n",
            "| 에폭 62 | 퍼플렉서티 1.52\n",
            "| 에폭 63 | 퍼플렉서티 1.52\n",
            "| 에폭 64 | 퍼플렉서티 1.52\n",
            "| 에폭 65 | 퍼플렉서티 1.51\n",
            "| 에폭 66 | 퍼플렉서티 1.51\n",
            "| 에폭 67 | 퍼플렉서티 1.51\n",
            "| 에폭 68 | 퍼플렉서티 1.51\n",
            "| 에폭 69 | 퍼플렉서티 1.50\n",
            "| 에폭 70 | 퍼플렉서티 1.50\n",
            "| 에폭 71 | 퍼플렉서티 1.50\n",
            "| 에폭 72 | 퍼플렉서티 1.49\n",
            "| 에폭 73 | 퍼플렉서티 1.49\n",
            "| 에폭 74 | 퍼플렉서티 1.49\n",
            "| 에폭 75 | 퍼플렉서티 1.49\n",
            "| 에폭 76 | 퍼플렉서티 1.49\n",
            "| 에폭 77 | 퍼플렉서티 1.48\n",
            "| 에폭 78 | 퍼플렉서티 1.48\n",
            "| 에폭 79 | 퍼플렉서티 1.48\n",
            "| 에폭 80 | 퍼플렉서티 1.48\n",
            "| 에폭 81 | 퍼플렉서티 1.47\n",
            "| 에폭 82 | 퍼플렉서티 1.47\n",
            "| 에폭 83 | 퍼플렉서티 1.47\n",
            "| 에폭 84 | 퍼플렉서티 1.47\n",
            "| 에폭 85 | 퍼플렉서티 1.47\n",
            "| 에폭 86 | 퍼플렉서티 1.47\n",
            "| 에폭 87 | 퍼플렉서티 1.46\n",
            "| 에폭 88 | 퍼플렉서티 1.46\n",
            "| 에폭 89 | 퍼플렉서티 1.46\n",
            "| 에폭 90 | 퍼플렉서티 1.46\n",
            "| 에폭 91 | 퍼플렉서티 1.46\n",
            "| 에폭 92 | 퍼플렉서티 1.46\n",
            "| 에폭 93 | 퍼플렉서티 1.45\n",
            "| 에폭 94 | 퍼플렉서티 1.45\n",
            "| 에폭 95 | 퍼플렉서티 1.45\n",
            "| 에폭 96 | 퍼플렉서티 1.45\n",
            "| 에폭 97 | 퍼플렉서티 1.45\n",
            "| 에폭 98 | 퍼플렉서티 1.45\n",
            "| 에폭 99 | 퍼플렉서티 1.45\n",
            "| 에폭 100 | 퍼플렉서티 1.44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uATkacckB8t1"
      },
      "source": [
        "# https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/common/trainer.py\r\n",
        "import time\r\n",
        "import numpy \r\n",
        "class RnnlmTrainer:\r\n",
        "    def __init__(self, model, optimizer):\r\n",
        "        self.model = model\r\n",
        "        self.optimizer = optimizer\r\n",
        "        self.time_idx = None\r\n",
        "        self.ppl_list = None\r\n",
        "        self.eval_interval = None\r\n",
        "        self.current_epoch = 0\r\n",
        "\r\n",
        "    def get_batch(self, x, t, batch_size, time_size):\r\n",
        "        batch_x = np.empty((batch_size, time_size), dtype='i')\r\n",
        "        batch_t = np.empty((batch_size, time_size), dtype='i')\r\n",
        "\r\n",
        "        data_size = len(x)\r\n",
        "        jump = data_size // batch_size\r\n",
        "        offsets = [i * jump for i in range(batch_size)]  # 배치에서 각 샘플을 읽기 시작하는 위치\r\n",
        "\r\n",
        "        for time in range(time_size):\r\n",
        "            for i, offset in enumerate(offsets):\r\n",
        "                batch_x[i, time] = x[(offset + self.time_idx) % data_size]\r\n",
        "                batch_t[i, time] = t[(offset + self.time_idx) % data_size]\r\n",
        "            self.time_idx += 1\r\n",
        "        return batch_x, batch_t\r\n",
        "\r\n",
        "    def fit(self, xs, ts, max_epoch=10, batch_size=20, time_size=35,\r\n",
        "            max_grad=None, eval_interval=20):\r\n",
        "        data_size = len(xs)\r\n",
        "        max_iters = data_size // (batch_size * time_size)\r\n",
        "        self.time_idx = 0\r\n",
        "        self.ppl_list = []\r\n",
        "        self.eval_interval = eval_interval\r\n",
        "        model, optimizer = self.model, self.optimizer\r\n",
        "        total_loss = 0\r\n",
        "        loss_count = 0\r\n",
        "\r\n",
        "        start_time = time.time()\r\n",
        "        for epoch in range(max_epoch):\r\n",
        "            for iters in range(max_iters):\r\n",
        "                batch_x, batch_t = self.get_batch(xs, ts, batch_size, time_size)\r\n",
        "\r\n",
        "                # 기울기를 구해 매개변수 갱신\r\n",
        "                loss = model.forward(batch_x, batch_t)\r\n",
        "                model.backward()\r\n",
        "                params, grads = remove_duplicate(model.params, model.grads)  # 공유된 가중치를 하나로 모음\r\n",
        "                if max_grad is not None:\r\n",
        "                    clip_grads(grads, max_grad)\r\n",
        "                optimizer.update(params, grads)\r\n",
        "                total_loss += loss\r\n",
        "                loss_count += 1\r\n",
        "\r\n",
        "                # 퍼플렉서티 평가\r\n",
        "                if (eval_interval is not None) and (iters % eval_interval) == 0:\r\n",
        "                    ppl = np.exp(total_loss / loss_count)\r\n",
        "                    elapsed_time = time.time() - start_time\r\n",
        "                    print('| 에폭 %d |  반복 %d / %d | 시간 %d[s] | 퍼플렉서티 %.2f'\r\n",
        "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, ppl))\r\n",
        "                    self.ppl_list.append(float(ppl))\r\n",
        "                    total_loss, loss_count = 0, 0\r\n",
        "\r\n",
        "            self.current_epoch += 1\r\n",
        "\r\n",
        "    def plot(self, ylim=None):\r\n",
        "        x = numpy.arange(len(self.ppl_list))\r\n",
        "        if ylim is not None:\r\n",
        "            plt.ylim(*ylim)\r\n",
        "        plt.plot(x, self.ppl_list, label='train')\r\n",
        "        plt.xlabel('반복 (x' + str(self.eval_interval) + ')')\r\n",
        "        plt.ylabel('퍼플렉서티')\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "\r\n",
        "def remove_duplicate(params, grads):\r\n",
        "    '''\r\n",
        "    매개변수 배열 중 중복되는 가중치를 하나로 모아\r\n",
        "    그 가중치에 대응하는 기울기를 더한다.\r\n",
        "    '''\r\n",
        "    params, grads = params[:], grads[:]  # copy list\r\n",
        "\r\n",
        "    while True:\r\n",
        "        find_flg = False\r\n",
        "        L = len(params)\r\n",
        "\r\n",
        "        for i in range(0, L - 1):\r\n",
        "            for j in range(i + 1, L):\r\n",
        "                # 가중치 공유 시\r\n",
        "                if params[i] is params[j]:\r\n",
        "                    grads[i] += grads[j]  # 경사를 더함\r\n",
        "                    find_flg = True\r\n",
        "                    params.pop(j)\r\n",
        "                    grads.pop(j)\r\n",
        "                # 가중치를 전치행렬로 공유하는 경우(weight tying)\r\n",
        "                elif params[i].ndim == 2 and params[j].ndim == 2 and \\\r\n",
        "                     params[i].T.shape == params[j].shape and np.all(params[i].T == params[j]):\r\n",
        "                    grads[i] += grads[j].T\r\n",
        "                    find_flg = True\r\n",
        "                    params.pop(j)\r\n",
        "                    grads.pop(j)\r\n",
        "\r\n",
        "                if find_flg: break\r\n",
        "            if find_flg: break\r\n",
        "\r\n",
        "        if not find_flg: break\r\n",
        "\r\n",
        "    return params, grads"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k-raRW2Y64zq",
        "outputId": "ab7fb3d2-f805-4000-ff5f-336d6fb961d1"
      },
      "source": [
        "# 위의 코드를 Trainer 클래스로 감추기\r\n",
        "# 하이퍼파라미터 설정\r\n",
        "batch_size = 10\r\n",
        "wordvec_size = 100\r\n",
        "hidden_size = 100  # RNN의 은닉 상태 벡터의 원소 수\r\n",
        "time_size = 5  # RNN을 펼치는 크기\r\n",
        "lr = 0.1\r\n",
        "max_epoch = 100\r\n",
        "\r\n",
        "# 학습 데이터 읽기\r\n",
        "corpus, word_to_id, id_to_word = load_data('train')\r\n",
        "corpus_size = 1000  # 테스트 데이터셋을 작게 설정\r\n",
        "corpus = corpus[:corpus_size]\r\n",
        "vocab_size = int(max(corpus) + 1)\r\n",
        "xs = corpus[:-1]  # 입력\r\n",
        "ts = corpus[1:]  # 출력（정답 레이블）\r\n",
        "\r\n",
        "# 모델 생성\r\n",
        "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\r\n",
        "optimizer = SGD(lr)\r\n",
        "trainer = RnnlmTrainer(model, optimizer)\r\n",
        "\r\n",
        "trainer.fit(xs, ts, max_epoch, batch_size, time_size)\r\n",
        "trainer.plot()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| 에폭 1 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 419.33\n",
            "| 에폭 2 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 431.19\n",
            "| 에폭 3 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 400.94\n",
            "| 에폭 4 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 322.30\n",
            "| 에폭 5 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 237.26\n",
            "| 에폭 6 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 220.65\n",
            "| 에폭 7 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 207.72\n",
            "| 에폭 8 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 205.23\n",
            "| 에폭 9 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 197.40\n",
            "| 에폭 10 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 190.97\n",
            "| 에폭 11 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 192.92\n",
            "| 에폭 12 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 189.91\n",
            "| 에폭 13 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 191.48\n",
            "| 에폭 14 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 186.26\n",
            "| 에폭 15 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 185.29\n",
            "| 에폭 16 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 189.80\n",
            "| 에폭 17 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 188.33\n",
            "| 에폭 18 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 183.54\n",
            "| 에폭 19 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 181.11\n",
            "| 에폭 20 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 181.60\n",
            "| 에폭 21 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 179.61\n",
            "| 에폭 22 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 178.44\n",
            "| 에폭 23 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 180.51\n",
            "| 에폭 24 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 178.29\n",
            "| 에폭 25 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 172.51\n",
            "| 에폭 26 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 175.77\n",
            "| 에폭 27 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 174.35\n",
            "| 에폭 28 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 175.37\n",
            "| 에폭 29 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 171.43\n",
            "| 에폭 30 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 167.83\n",
            "| 에폭 31 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 167.44\n",
            "| 에폭 32 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 163.61\n",
            "| 에폭 33 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 165.03\n",
            "| 에폭 34 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 165.98\n",
            "| 에폭 35 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 161.10\n",
            "| 에폭 36 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 161.09\n",
            "| 에폭 37 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 162.52\n",
            "| 에폭 38 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 154.89\n",
            "| 에폭 39 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 154.47\n",
            "| 에폭 40 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 150.33\n",
            "| 에폭 41 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 146.30\n",
            "| 에폭 42 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 147.27\n",
            "| 에폭 43 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 144.67\n",
            "| 에폭 44 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 143.79\n",
            "| 에폭 45 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 134.69\n",
            "| 에폭 46 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 134.13\n",
            "| 에폭 47 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 134.32\n",
            "| 에폭 48 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 131.90\n",
            "| 에폭 49 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 127.89\n",
            "| 에폭 50 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 121.43\n",
            "| 에폭 51 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 120.01\n",
            "| 에폭 52 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 115.94\n",
            "| 에폭 53 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 114.07\n",
            "| 에폭 54 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 111.25\n",
            "| 에폭 55 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 108.92\n",
            "| 에폭 56 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 104.42\n",
            "| 에폭 57 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 104.75\n",
            "| 에폭 58 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 99.11\n",
            "| 에폭 59 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 96.90\n",
            "| 에폭 60 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 92.91\n",
            "| 에폭 61 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 88.81\n",
            "| 에폭 62 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 85.91\n",
            "| 에폭 63 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 86.10\n",
            "| 에폭 64 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 82.19\n",
            "| 에폭 65 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 76.84\n",
            "| 에폭 66 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 75.70\n",
            "| 에폭 67 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 73.81\n",
            "| 에폭 68 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 71.29\n",
            "| 에폭 69 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 68.78\n",
            "| 에폭 70 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 65.34\n",
            "| 에폭 71 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 63.67\n",
            "| 에폭 72 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 60.42\n",
            "| 에폭 73 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 58.59\n",
            "| 에폭 74 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 55.49\n",
            "| 에폭 75 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 54.42\n",
            "| 에폭 76 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 53.47\n",
            "| 에폭 77 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 50.31\n",
            "| 에폭 78 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 48.19\n",
            "| 에폭 79 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 46.38\n",
            "| 에폭 80 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 43.60\n",
            "| 에폭 81 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 42.41\n",
            "| 에폭 82 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 40.39\n",
            "| 에폭 83 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 38.65\n",
            "| 에폭 84 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 37.88\n",
            "| 에폭 85 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 35.32\n",
            "| 에폭 86 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 33.97\n",
            "| 에폭 87 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 33.17\n",
            "| 에폭 88 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 30.88\n",
            "| 에폭 89 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 30.46\n",
            "| 에폭 90 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 28.74\n",
            "| 에폭 91 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 27.48\n",
            "| 에폭 92 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 26.36\n",
            "| 에폭 93 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 25.10\n",
            "| 에폭 94 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 24.17\n",
            "| 에폭 95 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 23.13\n",
            "| 에폭 96 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 22.32\n",
            "| 에폭 97 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 21.24\n",
            "| 에폭 98 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 20.34\n",
            "| 에폭 99 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 19.33\n",
            "| 에폭 100 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 18.36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48152 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48373 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54140 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54540 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47113 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49436 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54000 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48152 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48373 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54140 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54540 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47113 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49436 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54000 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgriJ9tbB9u6"
      },
      "source": [
        ""
      ],
      "execution_count": 97,
      "outputs": []
    }
  ]
}