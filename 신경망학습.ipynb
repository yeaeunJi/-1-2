{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "신경망학습.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMDTDGuhRSi43ROZK3De34E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeaeunJi/deep_learning-/blob/main/%EC%8B%A0%EA%B2%BD%EB%A7%9D%ED%95%99%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTbjj55FkLPp"
      },
      "source": [
        "# 신경망 학습\n",
        "- 학습이란 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것\n",
        "- 이 챕터에서는 신경망이 학습할 수 있도록 해주는 지표인 '손실함수'가 나옴\n",
        "  - 손실 함수의 최소 결과 값을 만드는 가중치 매개 변수를 찾는 것이 신경망 학습의 목표임\n",
        "  - 손실 함수의 값을 가급적 작게 만드는 기법 중 함수의 기울기를 활용하는 경사법을 배울 것임\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8Rbv_hwksYt"
      },
      "source": [
        "## 데이터에서 학습\n",
        "- 신경망의 특징은 데이터를 보고 학습할 수 있다는 것이며, 이를 통해 가중치 매개 변수의 값을 자동으로 결정 가능\n",
        "\n",
        "### 데이터 주도 학습\n",
        "- 알고리즘을 밑바닥부터 설계하는 대신 주어진 데이터를 활용하는 방법 존재\n",
        "  - 그 중 하나로 이미지에서 특징(feature)을 추출하고 그 특징의 패턴을 기계학습으로 기술하는 학습 방법이 있음 \n",
        "    * feature : 입력 데이터(입력 이미지)에서 본질적인 데이터(중요한 데이터)를 정확하게 추출할 수 있도록 설계된 변환기를 의미\n",
        "    - 이미지의 특징은 보통 벡터로 기술.\n",
        "    - 이미지 데이터를 벡터로 변환 후 그 데이터를 가지고 지도 학습 방식의 대표 분류 기번인 SVN, KNN 등으로 학습할 수 있음\n",
        "    - 사람이 생각한 특징을 사람이 설계하고 패턴 학습을 기계가 함\n",
        "  - 신경망(딥러닝)은 이미지를 있는 그대로 학습하고, 이미지에 포함된 중요한 특징까지 기계가 스스로 학습함\n",
        "    - 딥러닝을 종단간 기계학습(end-to-end machine learning, 입력에서 출력을 사람의 개입없이 얻음)라고 부르기도 함\n",
        "    - 이점 : 모든 문제를 같은 맥락에서 해결 가능\n",
        "        예) 개 사진 인식 == 사람 사진 인식 == 손글씨 '5' 인식"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbyyCmW1nwGC"
      },
      "source": [
        "### 훈련 데이터와 시험 데이터\n",
        "- 기계 학습에서는 데이터를 훈련 데이터(training data)와 시험 데이터(test data)로 나누어 학습과 실험을 수행하는 것이 일반적\n",
        "  - 훈련 데이터를 통해 최적의 매개변수를 가진 모델을 만들고, 시험 데이터를 사용하여 훈련한 모델을 평가\n",
        "  - 훈련 데이터로만 잘 작동되고 일반화되지 못하는 모델을 의미x\n",
        "\n",
        "    (처음보는 데이터를 통해서도 원하는 목표를 이루어내야함)\n",
        " - 기계 학습에서 과대적합(overfitting)을 피하는 것이 중요한 과제 중 하나임\n",
        " * 과대 적합 : 한 데이터셋에만 너무 잘 맞게 학습되어 다른 새로운 데이터로 제대로 성과를 내지 못하는 경우\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp914LfOqLNX"
      },
      "source": [
        "## 손실 함수(Loss function)\n",
        "- 일반적으로 오차제곱합과 교차 엔트로피 오차를 사용\n",
        "- 신경망 성능의 나쁨을 나타내는 지표 중 하나\n",
        "  - 현재 신경망이 훈련 데이터를 얼마나 잘 처리하지 못했는가를 보여줌\n",
        "  - 손실 함수에 -를 곱하면 '얼마나 좋은가'와 같은 지표로 변신 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnn-x21gq5Vv"
      },
      "source": [
        "### 오차제곱합(sum of squares for error, SSE)\n",
        "- 각 원소의 출력(추정값)과 정답의 차를 제곱한 후 그 총합을 구하는 것\n",
        "- 오차제곱합의 기준으로 오차가 더 작은 것이 정답에 더 가까울 것이라고 판단"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfrIWq5hjpMQ",
        "outputId": "92d9e7a2-145f-458e-a757-c20bb41b3cf7"
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]  #  신경망이 숫자 0 ~ 9까지 추론한 확률. 숫자 2일 확률이 가장 높다고 나옴\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # 정답 # 숫자 2 원핫인코딩\n",
        "\n",
        "def sum_squares_error(y, t) :\n",
        "  return 0.5*np.sum((y-t)**2)\n",
        "\n",
        "print(sum_squares_error(np.array(y), np.array(t)))\n",
        "\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]  #  신경망이 숫자 0 ~ 9까지 추론한 확률. 숫자 2일 확률이 가장 높다고 나옴\n",
        "print(sum_squares_error(np.array(y), np.array(t)))\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.09750000000000003\n",
            "0.5975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNgOqcPKksFe"
      },
      "source": [
        "### 교차 엔트로프 오차(cross entropy error, CEE)\n",
        "- 정답일 때의 출력이 전체 값을 정함\n",
        "- 정답에 해당하는 출력이 커질수록 0에 다가가다가, 출력이 1일 때 0이 됨\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSSv7j3X_ugQ",
        "outputId": "cc22a232-2339-429a-fd45-6bd90a9e3712"
      },
      "source": [
        "import numpy as np \n",
        "def cross_entropy_error(y,t) :\n",
        "  delta = 1e-7 # np.log() 함수에 0을 입력할 경우, 마이너스 무한대를 뜻하는 -inf가 되어 계산x\n",
        "  \n",
        "  return -np.sum(t*np.log(y+delta)) \n",
        "\n",
        "\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]  #  신경망이 숫자 0 ~ 9까지 추론한 확률. 숫자 2일 확률이 가장 높다고 나옴\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # 정답 # 숫자 2 원핫인코딩\n",
        "\n",
        "print(cross_entropy_error(np.array(y), np.array(t)))\n",
        "\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]  #  신경망이 숫자 0 ~ 9까지 추론한 확률. 숫자 2일 확률이 가장 높다고 나옴\n",
        "print(cross_entropy_error(np.array(y), np.array(t)))\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.510825457099338\n",
            "2.302584092994546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EMvR4ooAuOF"
      },
      "source": [
        "### 미니배치 학습\n",
        "- 훈련 데이터 모두에 대한 손실 함수의 합을 구하는 방법\n",
        "- 평균 손실 함수를 구하여 정규화함으로써 훈련 데이터 개수와 관계없이 언제든 통일된 지표를 얻을 수 있음\n",
        "\n",
        "- 하지만 빅데이터와 같은 경우, 모든 데이터를 대상으로 일일이 손실함수를 계산하는 것은 시간이 많이 소요될 수 있음\n",
        "  - 이럴 경우, 데이터의 일부로 전체의 근사치를 추론하여 사용해볼 수 있음\n",
        "    - 미니배치(mini-batch) : 훈련 데이터로부터 무작위로 일부만 골라 학습 수행\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUGL4aWgCayH",
        "outputId": "3cae90c6-3a8e-4b65-8270-4668168927c6"
      },
      "source": [
        "# coding: utf-8\n",
        "try:\n",
        "    import urllib.request\n",
        "except ImportError:\n",
        "    raise ImportError('You should use Python 3.x')\n",
        "import os.path\n",
        "import gzip\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
        "key_file = {\n",
        "    'train_img':'train-images-idx3-ubyte.gz',\n",
        "    'train_label':'train-labels-idx1-ubyte.gz',\n",
        "    'test_img':'t10k-images-idx3-ubyte.gz',\n",
        "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "__file__ = os.pardir\n",
        "# print(__file__)\n",
        "dataset_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "save_file = dataset_dir + \"/mnist.pkl\"\n",
        "\n",
        "train_num = 60000\n",
        "test_num = 10000\n",
        "img_dim = (1, 28, 28)\n",
        "img_size = 784\n",
        "\n",
        "\n",
        "def _download(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    if os.path.exists(file_path):\n",
        "        return\n",
        "\n",
        "    print(\"Downloading \" + file_name + \" ... \")\n",
        "    urllib.request.urlretrieve(url_base + file_name, file_path)\n",
        "    print(\"Done\")\n",
        "    \n",
        "def download_mnist():\n",
        "    for v in key_file.values():\n",
        "       _download(v)\n",
        "        \n",
        "def _load_label(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "    print(\"Done\")\n",
        "    \n",
        "    return labels\n",
        "\n",
        "def _load_img(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")    \n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "    data = data.reshape(-1, img_size)\n",
        "    print(\"Done\")\n",
        "    \n",
        "    return data\n",
        "    \n",
        "def _convert_numpy():\n",
        "    dataset = {}\n",
        "    dataset['train_img'] =  _load_img(key_file['train_img'])\n",
        "    dataset['train_label'] = _load_label(key_file['train_label'])    \n",
        "    dataset['test_img'] = _load_img(key_file['test_img'])\n",
        "    dataset['test_label'] = _load_label(key_file['test_label'])\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "def init_mnist():\n",
        "    download_mnist()\n",
        "    dataset = _convert_numpy()\n",
        "    print(\"Creating pickle file ...\")\n",
        "    with open(save_file, 'wb') as f:\n",
        "        pickle.dump(dataset, f, -1)\n",
        "    print(\"Done!\")\n",
        "\n",
        "def _change_one_hot_label(X):\n",
        "    T = np.zeros((X.size, 10))\n",
        "    for idx, row in enumerate(T):\n",
        "        row[X[idx]] = 1\n",
        "        \n",
        "    return T\n",
        "    \n",
        "\n",
        "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
        "    \"\"\"MNIST 데이터셋 읽기\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    normalize : 이미지의 픽셀 값을 0.0~1.0 사이의 값으로 정규화할지 정한다.\n",
        "    one_hot_label : \n",
        "        one_hot_label이 True면、레이블을 원-핫(one-hot) 배열로 돌려준다.\n",
        "        one-hot 배열은 예를 들어 [0,0,1,0,0,0,0,0,0,0]처럼 한 원소만 1인 배열이다.\n",
        "    flatten : 입력 이미지를 1차원 배열로 만들지를 정한다. \n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    (훈련 이미지, 훈련 레이블), (시험 이미지, 시험 레이블)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(save_file):\n",
        "        init_mnist()\n",
        "        \n",
        "    with open(save_file, 'rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "    \n",
        "    if normalize:\n",
        "        for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].astype(np.float32)\n",
        "            dataset[key] /= 255.0\n",
        "            \n",
        "    if one_hot_label:\n",
        "        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])\n",
        "        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])    \n",
        "    \n",
        "    if not flatten:\n",
        "         for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
        "\n",
        "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) \n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     init_mnist()\n",
        "\n",
        "# MNIST 데이터셋을 내려받아 그 이미지를 넘파이 배열로 변화해주는 파이썬 스크립트 사용\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "# from dataset.mnist import load_mnist\n",
        "# load_mnist()\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(t_train.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cJokLnWAKP2",
        "outputId": "b546c95d-9aed-435d-97ba-fce0aa19fec1"
      },
      "source": [
        "# 훈련 데이터에서 지정한 수의 데이터를 무작위로 추출하는 코드 구현\n",
        "# 무작위로 10장만 \n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 10\n",
        "batch_mask = np.random.choice(train_size, batch_size) # 지정한 범위의 수중 무작위로 원하는 개수만 꺼냄 # 추출할 데이터의 인덱스로 사용\n",
        "x_batch = x_train[batch_mask]\n",
        "t_batch = t_train[batch_mask]\n",
        "\n",
        "print(batch_mask)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 3902 45493 39933 26072 43600  1118 45078 40550 57137 17610]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzSCqtNXC8dp"
      },
      "source": [
        "# 무작위 추출된 인덱스로 미니배치 추출 후 손실함수도 미니 배치로 계산 가능"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si7Ec8qREITi"
      },
      "source": [
        "### (배치용) 교차 엔트로피 오차 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH4xlVvsEFny"
      },
      "source": [
        "# 데이터가 하나일 때와 배치로 묶여 있는 경우 모두 처리할 수 있는 교차 엔트로피 오차 구현\n",
        "def cross_entropy_error(y, t) :\n",
        "  if y.ndim == 1 : # 데이터가 한개\n",
        "    t = t.reshape(1, t.size)\n",
        "    y = y.reshape(1, y.size)\n",
        "  \n",
        "  batch_size = y.shape[0]\n",
        "  return -np.sum(t * np.log(y+1e-7)) / batch_size # 배치 크기로 나누어 정규화하고, 이미지 1장당 평균 교차 엔트로피 오차를 계산"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjBXTGHtxo7X"
      },
      "source": [
        "# 만약 정답 레이블이 원핫인코딩이 아닌 숫자 레이블이라면 다음과 같이 교차 엔트로피 오차를 구현 가능\n",
        "def cross_entropy_error(y, t) :\n",
        "  if y.ndim == 1 :\n",
        "    t = t.reshape(1, t.size)\n",
        "    y = y.reshape(1, y.size)\n",
        "  \n",
        "  batch_size = y.shape[0] # 데이터 수\n",
        "  return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size \n",
        "  # 핵심 : 원핫인코딩일 때 t가 0인 원소는 교차 엔트로피 오차도 0이므로 그 계산 무시해도 좋다\n",
        "  # ===> 정답에 해당하는 신경망의 출력만으로 계산 가능하다는 의미"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG-fTBfzzvTO"
      },
      "source": [
        "### 손실 함수를 설정하는 이유는 무엇인가\n",
        "  - 신경망 학습에서는 최적의 매개변수(가중치와 편향)을 탐색할 대 손실 함수의 값을 가능한 한 작게 하는 매개변수 값을 찾는 것이 목표.\n",
        "  - 이때 매개변수의 미분(정확히는 기울기)을 계산하고, 그 값을 단서로 매개변수의 값을 서서히 갱신하는 과정을 반복하여 최적의 매개변수를 찾음\n",
        "  - 어떤 한 신경망의 가중치 매개변수의 손실함수의 미분이란 '가중치 매개변수의 값을 아주 조금 변화시켰을 때, 손실 함수가 어떻게 변화하는가'를 의미함\n",
        "    - 미분 값 < 0 : 가중치 매개변수를 양의 방향으로 변화시켜 손실 함수의 값 감소\n",
        "    - 미분 값 > 0 : 가중치 개매변수를 음의 방향으로 변화시켜 손실 함수의 값 감소\n",
        "    - 미분 값 = 0 : 어느 쪽으로 움직여도 손실 함수의 값은 줄어들지 않으므로 가중치 매개변수의 갱신 중지\n",
        "\n",
        "- 정확도가 아닌 손실 함수의 값을 찾는 이유는 무엇일까?\n",
        "  - 정확도를 지표로 삼을 경우, 매개변수의 미분이 대부분의 장소에서 0이 되어 매개변수 갱신을 할 수 없기 때문\n",
        "    - 예) 한 신경망이 100장의 훈련 데이터 중 32장을 올바르게 인식\n",
        "          정확도 : 32%\n",
        "      \n",
        "      가중치 매개변수의 값을 약간 조정해도 정확도는 바뀌지 않고 일정하게 유지되거나 혹은 연속적인 변화가 아닌 32 --> 33, 34%와 같이 불연속적인 값으로 바뀐다고 함...\n",
        "\n",
        "    - 하지만, 손실 함수를 지표롤 삼을 경우, 매개 변수의 값이 조금 변화하면 그에 반응하여 손실 함수의 값도 연속적으로 변화함\n",
        "\n",
        "  - 계단 함수를 미분할 경우, 대부분의 장소에서 0이되는 것과 비슷\n",
        "  - 즉, 매개변수의 미세한 변화가 일으키는 것을 계단 함수가 말살하여 손실 함수의 값에는 아무런 변화가 나타나지 않음(시그모이드 함수의 기울기는 0이 아님)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnPIxKtfyzla"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}